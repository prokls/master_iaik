\chapter{SAT features}
\label{ch:features}
%
At the very beginning I was very intrigued by the question
\enquote{What is an \enquote{average} SAT problem?}. Answers to this
question can help to optimize SAT solver memory layouts.
Specifically for this thesis I wanted to find out whether
our problems distinguish from \enquote{average} problems in any
way such that we can use this distinction for runtime optimization.

I came up with 8 questions related to basic properties of SAT problems
we will discuss in depth in this section:
\begin{enumerate}
\item Given an arbitrary literal. What is the percentage it is positive?
\item What is the variables / clauses ratio?
\item How many literals occur only either positive or negative?
\item What is the average and longest clause length among CNF benchmarks?
\item How many Horn clauses exist in a CNF?
\item Are there any tautological clauses?
\item Are there any CNF files with more than one connected variable component?
\item How many variables of a CNF are covered by unit clauses?
\end{enumerate}

We will now define the terms used in those questions.

\section{SAT features and CNF analysis}
\label{sec:features-analysis}
%
\index{SAT feature}
\index{Feature value}
\begin{defi}[SAT feature]
  A \emph{SAT feature} is a statistical value (named \emph{feature value})
  retrievable from some given SAT problem.
\end{defi}

The most basic example of a SAT feature is the number of variables and clauses
of a given SAT problem. This SAT feature is stored in the CNF header of a SAT
problem encoded in the DIMACS format.

The general goal is to write a tool which evaluates several SAT features at the same
time and retrieve them for comparison with other problems. Therefore it should be
computationally easy to evaluate SAT features of a given SAT problem. A suggested
computational limit is given with polynomial complexity in terms of number of
variables and number of clauses for memory as well as runtime for evaluation algorithms.
Sticking to this convention implies that evaluation of satisfiability must not be
necessary to evaluate a SAT feature under the assumption that \cPneqNP. Hence the
number of valid models cannot be a SAT feature as far as satisfiability needs to
be determined. But no actual hard computational limit is defined.

\section{Related work}
\label{sec:features-related}
%
The most similar resource I found looking at SAT features was the
SATzilla project~\cite{satzilla2004,satzilla2008} in 2012. The authors systematically defined
138 SAT~features categorized in 12 groups. Some features are only evaluated conditionally.
The features themselves are not defined formally, but an implementation is provided bundled
with example data. The following list provides an excerpt of the features:

\begin{description}
\item[\satfeature{nvarsOrig}] number of variables defined in the CNF header
\item[\satfeature{nvars}] number of active variables
\item[\satfeature{reducedVars}] \satfeature{nvarsOrig} - \satfeature{nvars}, divided by \satfeature{nvars}
\item[\satfeature{vars-clauses-ratio}] nvars divided by number of active clauses
\item[\satfeature{POSNEG-RATIO-CLAUSE-mean}] mean of $2 \cdot \left\| 0.5 - {\text{pos}}/{\text{length}}\right\|$ where $\text{pos}$ is the number of positive literals and $\text{length}$ clause length of a specific clause
\item[\satfeature{POSNEG-RATIO-CLAUSE-entropy}] like \satfeature{POSNEG-RATIO-CLAUSE-mean} but entropy
\item[\satfeature{TRINARY+}] number of clauses with clause length 1, 2 or 3 divided by number of active clauses
\item[\satfeature{HORNY-VAR-min}] minimum number of times a variable occurs in a Horn clause
\item[\satfeature{cluster-coeff-mean}]
   let neighbors of a clause be all clauses containing any literal negated
   and let clauses $c_1$ and $c_2$ be conflicting if $c_1$ contains literal $l$ and $c_2$ contains $-l$,
   then return the mean of $2$ times the number of conflicting neighbors of a clause $c$
   divided by the number of unordered pairs of neighbors,
   returned iff computable within 20 seconds for all clauses
\end{description}

Please recognize that active clauses are the unsatisfied clauses after BCP has been applied.
Equivalently active variables are remaining variables after application of BCP.

Many SAT solvers collect feature values to improve algorithm selection,
restart strategies and estimate problem sizes. Recent trends to apply Machine
Learning to SAT solving imply feature evaluation. SAT features and the resulting
satisfiability runtime are used as training data for Machine Learning. One example
using SAT features for algorithm selection is ASlib~\cite{aslib}.

\section{Statistical features}
\label{sec:features-stats}
%
For our SAT~features we need to define some basic statistical terminology.
Let $x_1, x_2, \ldots, x_n$ be a finite sequence of numbers ($n \in \mathbb N$).
\begin{description}
  \item[Arithmetic mean] (or short: mean)
    is defined as
    \[ \overline{x} = \frac1n \sum_{i=1}^n x_i \]
  \item[Standard deviation] (or short: sd)
    with mean $\overline{x}$ is defined as
    \[ \sigma(x) = \sqrt{\frac1n \sum_{i=1}^n (x_i - \overline{x})} \]
  \item[Median]
    with $x_1 \leq x_2 \leq \ldots \leq x_n$
    (i.e. sorted ascendingly) is defined as
    \[
       m = \begin{cases}
         x_{\lceil \text{mid}\rceil} & \text{if } n \text{ odd} \\
         \frac{x_{\text{mid}} + x_{\text{mid} + 1}}{2} & \text{if } n \text{ even}
       \end{cases}
       \quad\text{ with } \text{mid} = \frac{n}{2}
    \]
    and often considered more \enquote{robust} than the arithmetic mean.
  \item[Entropy]
    is defined according to Claude Shannon's information theory:
    \[ H(x) = -\sum_{i=1}^n x_i \cdot \log_2(x_i) \]
    where $0 \cdot \log_2(0) \coloneqq 0$.
\end{description}

Furthermore \emph{count} refers to the number of elements $n$,
\emph{largest} refers to the maximum element $\max_{1 \leq i \leq n}(x_i)$
and \emph{smallest} refers to the minimum element $\min_{1 \leq i \leq n}(x_i)$.

\section{Suggested SAT features}
\label{sec:features-suggested}
%
We wrote a tool called cnf-analysis. The evaluated features are partially inspired
by SATzilla and lingeling. The latter prints basic statistics for every CNF it
evaluates.

A summary of our suggested SAT features is given:

\begin{description}
\item[\satfeature{clause\_variables\_sd\_mean}] \hfill{} \\
  mean of sd of variables in a clause
\item[\satfeature{clauses\_length\_(largest, smallest, mean, median, sd)}] \hfill{} \\
  statistics related to the clause length
\item[\satfeature{connected\_(literal, variable)\_components\_count}] \hfill{} \\
  two literals (variables) are connected if they occur in some clause together,
  count the number of connected components
\item[\satfeature{definite\_clauses\_count}] \hfill{} \\
  number of definite clauses in the CNF
\item[\satfeature{existential\_literals\_count}] \hfill{} \\
  number of existential literals in the CNF
\item[\satfeature{existential\_positive\_literals\_count}] \hfill{} \\
  number of positive, existential literals in the CNF
\item[\satfeature{(false, true)\_trivial}] \hfill{} \\
  is the CNF satisfied if all variables are claimed to be false (true)?
\item[\satfeature{goal\_clauses\_count}] \hfill{} \\
  number of goal clauses in the CNF
\item[\satfeature{literals\_count}] \hfill{} \\
  number of literals in the CNF (i.e. sum of clause lengths)
\item[\satfeature{literals\_frequency\_$k$\_to\_$k+5$}] \hfill{} \\
  let $n_l$ be the literal frequency of literal $l$,
  count the number of $n_l$ satisfying $\frac{k}{100} \leq n_l < \frac{k+5}{100}$
  where $k$ is a variable in $\{0,5,10,\ldots,90,95\}$ and $k=95$ counts
  $\frac{k}{100} \leq n_l \leq \frac{k+5}{100}$.
\item[\satfeature{literals\_frequency\_(largest, smallest, mean, median, sd)\_entropy}] \hfill{} \\
  statistics related to literal frequencies
\item[\satfeature{literals\_occurence\_one\_count}] \hfill{} \\
  number of literals with occurence $1$
\item[\satfeature{nbclauses}, \satfeature{nbvars}] \hfill{}
  number of clauses (variables) as defined in the CNF header
\item[\satfeature{negative\_literals\_in\_clause\_(smallest, largest, mean)}] \hfill{} \\
  statistics related to number of negative literals in clauses
\item[\satfeature{(positive, negative)\_unit\_clause\_count}] \hfill{} \\
  number of unit clauses with a positive (negative) literal
\item[\satfeature{positive\_literals\_count}] \hfill{} \\
  number of positive literals in CNF
\item[\satfeature{positive\_literals\_in\_clause\_(largest, smallest, mean, median, sd)}] \hfill{} \\
  statistics related to number of positive literals in clauses
\item[\satfeature{positive\_negative\_literals\_in\_clause\_ratio\_(mean, entropy)}] \hfill{} \\
  let $r_c$ be the number of positive literals divided by clause length of clause $c$,
  mean and related of all $r_c$
\item[\satfeature{positive\_negative\_literals\_in\_clause\_ratio\_mean}] \hfill{} \\
  mean of all $r_c$
\item[\satfeature{tautological\_literals\_count}] \hfill{} \\
  number of clauses which contain a tautological literal
\item[\satfeature{two\_literals\_clause\_count}] \hfill{} \\
  number of clauses with two literals
\item[\satfeature{variables\_frequency\_$k$\_to\_$k+5$}] \hfill{} \\
  same as \satfeature{literals\_frequency\_$k$\_to\_$k+5$} but for variables
\item[\satfeature{variables\_frequency\_(largest, smallest, mean, median, sd, entropy)}] \hfill{} \\
  same as \satfeature{literals\_frequency} but for variables
\item[\satfeature{variables\_used\_count}] \hfill{} \\
  number of variables with occurence greater 0
\end{description}

\section{Evaluation efficiency}
\label{sec:features-efficiency}
%
The resource requirements of those features have been classified:
\begin{description}
  \item[Type 1] read the files as bytes, a DIMACS parser is not necessary, constant memory is used
  \item[Type 2] features understand what a clause is, but still need constant memory
  \item[Type 3] subquadratic runtime and linear memory
  \item[Type 4] unrestricted
\end{description}
%
Memory and runtime is always considered in comparison with the filesize.

This classification should support future considerations regarding feature evaluation tools.
The suggested SAT features above have been explicitly selected to avoid Type 4 implementations to limit the time to compute features.
The Python implementation triggered MemoryErrors on a computer with 4~GB RAM for a 770~MB CNF file.
Followingly a much more efficient Go implementation was implemented which requires much less memory and is much faster.
\texttt{bench\_573.smt2.cnf} took 1 second in Go instead of 2 minutes in Python.
However, the data evaluated is less accurate compared to Python, because Python unlike Go provide nice implementation of statistical tools in the standard library.

In the following section we want to evaluate SAT features and
compare test cases.

\section{CNF dataset}
\label{sec:features-dataset}
%
To evaluate CNF features of a representative set of CNF files, it was necessary to identify equivalent CNF files in the best possible way.
Therefore I defined a hashing algorithm standardizing the CNF input provided to a SHA1 instance. Every CNF file is identifiable by its
\enquote{cnfhash 2.0.0} hash value.

In the next step a complete set of CNF files of previous SAT competitions was collected.
The following CNF file collections have been considered:

\begin{itemize}
  \itemsep2pt
  \item SAT Race 2008
  \item SAT09 Competition
  \item SAT-Race 2010
  \item SAT11 Competition
  \item SAT Challenge 2012
  \item SAT Competition 2013
  \item SAT Competition 2014
  \item SAT-Race 2015
  \item SAT Competition 2016
  \item SATlib
\end{itemize}
The benchmarks are mostly contributed by the participants of the associated conferences.
Others are reused from previous years. Individual projects allow to generate CNF files
for specific problems in a selectable problem size; such as 

Some files turned out to be problematic. In SATlib, 3 gzipped files couldn't be decompressed and several files
contain empty clauses. Empty clauses are assumed to immediately falsify the CNF and are therefore pointless.
I removed trailing zeros in CNFs. Variants of the DIMACS standard also expect lines with a percent symbol to
terminate the CNF. Besides those minor issues documented as part of the cnf-analysis project,
many gigabytes of CNF files have been evaluated.

\section{The average SAT problem}
\label{sec:features-average}
%
\begin{prop}
  The set of public benchmarks in SAT competitions between 2008 and 2015
  represent average SAT problems
\end{prop}

It is important to point out that public benchmark files are specifically chosen
to be evaluated before a conference is held. Hence they are expected to terminate
within a given time frame and are therefore not oversized. On the one hand this
ensures that the problems are actually solvable, however they might not be a
representative selection. At this point no better data set is available and therefore
we proceeded with this dataset.

According to my results, an average SAT problem consists of:
\begin{itemize}
  \item 83,650 clauses in average ranging from 21 to 53,616,734
  \item The longest clause we found had 61,473~literals, but the longest clause of CNFs typically covers 17 literals.
  \item At least 114 up to 150,609,758 literals were found in a CNF.
  \item The clause-variables ratio lies between 1.5 and 27720 with mean 8.35 and $\sigma = 189$.
  \item The average length of a clause is expected to be 3.
  \item In average a CNF file has 67 connected variable components.
  \item In average 31,315 clauses are definite clauses and 29,995 clauses are goal clauses.
  \item In average a literal occurs in 1.3~\% of the clauses of the CNF.
  \item 48~\% of literals in a clause are positive.
  \item The arithmetic mean tells 137 unit clauses per CNF file can be expected, but the median tells it is mostly 0.
  \item The largest variable found was 13,842,706 and 13,829,558~variables were used at most.
\end{itemize}
