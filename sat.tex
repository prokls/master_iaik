\renewcommand*\chappic{img/satisfiability.pdf}
\renewcommand*\chapquote{What idiot called them logic errors rather than bool shit?}
\renewcommand*\chapquotesrc{Unknown}
\chapter{Satisfiability}
\label{ch:sat}
%
Boolean algebra allows us to describe functions over two-valued variables.
Satisfiability is the question for an assignment such that a function
evaluates to true. Satisfiability problems are solved by SAT~solvers.
We discuss the basic theory behind satisfiability. We will learn that any
computation can be represented as satisfiability problem. In Chapter~\ref{ch:enc}
we will represent a differential cryptanalysis problem such that it is
solvable iff the corresponding SAT~problem is satisfiable.

\section{Basic notation and definitions}
\label{sec:sat-intro}
%
\index{Boolean function}
\begin{defi}[Boolean function]
  A \emph{Boolean function} is a mapping $h: X \to Y$ with $X = \left\{0,1\right\}^n$
  for $n \in \mathbb N_{\geq 1}$ and $Y = \left\{0,1\right\}$.
\end{defi}

\index{Assignment}
\begin{defi}[Assignment]
  A \emph{$k$-assignment} is an element of $\left\{0,1\right\}^k$.

  \noindent
  Let $f$ be some $k$-ary Boolean function.
  An \emph{assignment for function $f$} is any $k$-assignment.
\end{defi}

\index{Truth table}
\begin{defi}[Truth table]
  Let $f$ be some $k$-ary Boolean function.
  The \emph{truth table of Boolean function $f$} assigns
  truth value $0$ or $1$ to any assignment of $f$.
\end{defi}

Boolean functions are characterized by their corresponding truth table.

\begin{table}[pt]
  \centering
  \subfloat[\boolf{AND}]{%
    \begin{tabular}{cc|c}
      $x_1$ & $x_2$ & $f(x_1, x_2)$ \\
     \hline
      $1$ & $1$ & $1$ \\
      $1$ & $0$ & $0$ \\
      $0$ & $1$ & $0$ \\
      $0$ & $0$ & $0$
    \end{tabular}
  }
  ~
  \subfloat[\boolf{OR}]{%
    \begin{tabular}{cc|c}
      $x_1$ & $x_2$ & $f(x_1, x_2)$ \\
     \hline
      $1$ & $1$ & $1$ \\
      $1$ & $0$ & $1$ \\
      $0$ & $1$ & $1$ \\
      $0$ & $0$ & $0$
    \end{tabular}
  }
  ~
  \raisebox{13.6pt}{%
    \subfloat[\boolf{NOT}]{%
      \begin{tabular}{c|c}
        $v$ & $f(v)$ \\
       \hline
        $1$ & $0$ \\
        $0$ & $1$
      \end{tabular}
    }%
  }%
  \caption{Truth tables for \boolf{AND}, \boolf{OR} and \boolf{NOT}}
  \label{tab:andornot-truthtables}
\end{table}

Table~\ref{tab:andornot-truthtables} shows example truth tables for
the Boolean \boolf{AND}, \boolf{OR} and \boolf{NOT} functions.
A different definition of the three functions is given the following way:

\index{AND (Boolean function)}
\index{OR (Boolean function)}
\index{NOT (Boolean function)}
\begin{defi}
  Let \boolf{AND}, \boolf{OR} and \boolf{NOT} be three Boolean functions.
  \begin{itemize}[noitemsep,topsep=0pt]
    \item
      \boolf{AND} maps $X = \left\{0,1\right\}^2$
      to $1$ if all values of $X$ are $1$.
    \item
      \boolf{OR} maps $X = \left\{0,1\right\}^2$
      to $1$ if any value of $X$ is $1$.
    \item
      \boolf{NOT} maps $X = \left\{0,1\right\}^1$
      to $1$ if the single value of $X$ is $0$.
  \end{itemize}
  All functions return $0$ in the other case.

  Those functions are denoted $a_0 \land a_1$, $a_0 \lor a_1$
  and $\neg a_0$ respectively, for input parameters $a_0$ and $a_1$.
\end{defi}

It is interesting to observe, that any Boolean function can be represented
using only these three operators. This can be proven by complete induction
over the number of arguments $k$ of the function.

Let $k = 1$. Then we consider any possible $2$-assignment for one input
variable $x_1$ and one value of $f(x_1)$. Then four truth tables are possible
listed in Table~\ref{tab:unary-f}. The description shows the corresponding
definition of $f$ using \boolf{AND}, \boolf{OR} and \boolf{NOT} only.

Now let $g$ be some $k$-ary function. Let $(a_0, a_1, \ldots, a_k)$ be the
$k$ input arguments to $g$ and $x_1 \coloneqq g(a_0, a_1, \ldots, a_k)$.
Then we can again look at Table~\ref{tab:unary-f} to discover that 4 cases
are possible: 2 cases where the return value of our new $(k+1)$-ary function
depends on value $x_1$ and 2 cases where the return value is constant.

This completes our proof.

\begin{table}[ht]
  \centering
  \subfloat[$f: x \mapsto 1$]{%
    \begin{tabular}{cc}
      $x_1$ & $f(x_1)$ \\
     \hline
      $1$ & $1$ \\
      $0$ & $1$
    \end{tabular}
  }
  ~
  \subfloat[$f: x \mapsto x$]{%
    \begin{tabular}{cc}
      $x_1$ & $f(x_1)$ \\
     \hline
      $1$ & $1$ \\
      $0$ & $0$
    \end{tabular}
  }
  ~
  \subfloat[$f: x \mapsto \neg x$]{%
    \begin{tabular}{cc}
      $x_1$ & $f(x_1)$ \\
     \hline
      $1$ & $0$ \\
      $0$ & $1$
    \end{tabular}
  }
  ~
  \subfloat[$f: x \mapsto 0$]{%
    \begin{tabular}{cc}
      $x_1$ & $f(x_1)$ \\
     \hline
      $1$ & $0$ \\
      $0$ & $0$
    \end{tabular}
  }%
  \caption{Unary $f$ and its four possible cases}
  \label{tab:unary-f}
\end{table}

Boolean functions have an important property which is described
in the following definition:

\index{Satisfiability}
\index{Assignment}
\index{Model}
\begin{defi}
  A Boolean function $f$ is \emph{satisfiable} iff there exists at least one
  input $x \in X$ such that $f(x) = 1$.
  Every input $x \in X$ satisfying this property is called \emph{model}.
\end{defi}

The corresponding tool to determine satisfiability is defined as follows:

\index{SAT solver}
\begin{defi}
  A \emph{SAT solver} is a tool to determine satisfiability (SAT or UNSAT)
  of a Boolean function. If satisfiability is given, it returns some model.
\end{defi}

\subsection{Computational considerations}
\label{sec:sat-complexity}
%
The generic complexity of SAT determination is given by $2^n$ for $n$ Boolean variables.

Let $n$ be the number of variables of a Boolean function.
No known algorithm exists to determine satisfiability in polynomial runtime.
This means no algorithm solves the SAT problem with runtime behavior
which depends polynomially on the growth of $n$.

This is known as the famous {\cP $\overset{?}{\neq}$ \cNP} problem.

\index{Unit propagation}
However, SAT solver can take advantage of the problem's description.
For example consider function $f$ in Display~\ref{eq:3f}.
\begin{align} f(x_0, x_1, x_2) &= x_0 \land (\neg x_1 \lor x_2) \label{eq:3f} \end{align}
Instead of trying all possible 8~cases for 3~Boolean variables,
we can immediately see that $x_0$ is required to be $1$.
So we don't need to test $x_0 = 0$ and can skip 4~cases.
This particular strategy is called \emph{unit propagation}.

\subsection{SAT competitions}
\label{sec:sat-competitions}
%
SAT research is heavily concerned with finding good heuristics to find some model
for a given SAT problem as fast as possible. Biyearly
\href{http://satcompetition.org/}{SAT competitions} take place to challenge
SAT solvers in a set of benchmarks. The committee evaluates the most successful
SAT solvers solving the most problems within a given time frame.

SAT~2016 is currently ongoing, but in 2014 lingeling by Armin Biere has won first prize in
the Application benchmarks track and second prize in the Hard Combinatorial benchmarks
track for SAT and UNSAT instances respectively. Its parallelized sibling plingeling
and Cube \& Conquer sibling treengeling have won prizes in parallel settings.

In chapter~\ref{ch:results} we will look at runtime results shown by (but not limited to)
those SAT solvers.

%\section{Satisfiability of hash algorithm states}
%\label{sec:intro-algo-sat}
%%
%We discussed Boolean functions and satisfiability. At the same time we looked
%at basic properties of hash algorithms. But the question remains how we can
%link those areas together? This section is dedicated to this question.

%\index{Algorithm}
%\index{I/O Algorithm}
%\begin{defi}
%  An \emph{algorithm} is a step-wise set of instructions to solve a problem.
%  An \emph{I/O algorithm} transforms given input values to output values.
%\end{defi}

%Hash algorithms are one example of I/O algorithms.

%I/O algorithms can be implemented as a sequence of instructions for computers.
%At the same time I/O algorithms can be represented as combination of Boolean
%functions. This claim is backed in more detail in Section~\ref{sec:sat-dimacs}
%with Theorem~\ref{thm:all-cnf}. It follows immediately that we can represent
%I/O algorithms such as hash algorithms entirely as Boolean function.

%\begin{theorem}
%  Every algorithm can be represented as Boolean function.
%\end{theorem}

%\index{Least significant bit}
%\index{Most significant bit}
%We consider 2-bit addition as small example. Let $a_{i}$ be the first argument
%where $i$ denotes the binary position. If $i=0$, the \emph{least significant bit}
%(LSB) is considered. If $i=1$, the \emph{most significant bit} (MSB) is considered.

%Let $b_{i}$ be the second argument and $s_{i}$ be the output value.
%Furthermore $c_{i}$ is the carry bit, where $c_1$ is left out, because
%it is not used in 2-bit addition. This model of 2-bit addition as Boolean
%function can be seen in Figure~\ref{fig:intro-2bit-addition}.

%\begin{figure}
%  \begin{center}
%    \begin{tabular}{lrcc}
%      1st arg: &   & $a_{1}$ & $a_{0}$ \\
%      2nd arg: & + & $b_{1}$ & $b_{0}$ \\
%    \hline
%      carry:   &   &         & $c_0$ \\
%      sum:     & = & $s_{1}$ & $s_0$
%    \end{tabular}
%    \hspace{10pt}~$\leadsto$\hspace{10pt}%
%    \begin{minipage}{50pt}%
%      \begin{flalign*}
%        s_0 &= \boolf{XOR}(a_0, b_0) &\\
%        c_0 &= a_0 \land b_0 &\\
%        s_1 &= \boolf{XOR}(a_0, b_0, c_0) &
%      \end{flalign*}
%    \end{minipage}
%  \end{center}
%  \caption{Modelling 2bit addition (left) as Boolean function (right)}
%  \label{fig:intro-2bit-addition}
%\end{figure}


\section{The DIMACS de-facto standard}
\label{sec:sat-dimacs}
%
\index{Conjunction}
\index{Disjunction}
\index{Literal}
\index{Positive literal}
\index{Negative literal}
\index{Conjunctive Normal Form}
\begin{defi}
  A \emph{conjunction} is a sequence of Boolean functions combined using
  a logical OR. A \emph{disjunction} is a sequence of Boolean functions
  combined using a logical AND. A \emph{literal} is a Boolean variable
  (\emph{positive}) or its negation (\emph{negative}).

  A SAT problem is given in \emph{Conjunctive Normal Form} (CNF) if
  the problem is defined as conjunction of disjunctions of literals.
\end{defi}

A simple example for a SAT problem in CNF is the exclusive OR (XOR).
It takes two Boolean values $a$ and $b$ as arguments and returns true
if and only if the two arguments differ.
{
\setlength{\abovedisplayskip}{5pt}
\setlength{\belowdisplayskip}{5pt}
\setlength{\abovedisplayshortskip}{0pt}
\setlength{\belowdisplayshortskip}{0pt}
\begin{align} (a \lor b) \land (\neg a \lor \neg b) \label{eq:xor}\end{align}
}
Display~\ref{eq:xor} shows one conjunction (denoted $\land$) of two disjunctions
(denoted $\lor$) of literals (denoted $a$ and $b$ where prefix $\neg$ represents
negation). This structure constitutes a CNF.

\index{Disjunctive Normal Form}
Analogously we define a \emph{Disjunctive Normal Form} (DNF) as disjunction
of conjunctions of literals. The negation of a CNF is in DNF, because literals
are negated and conjunctions become disjunctions, vice versa.

\begin{theorem}
  \label{thm:all-cnf}
  Every Boolean function can be represented as CNF.
\end{theorem}

Theorem~\ref{thm:all-cnf} is easy to prove.
% Consider null-ary functions as
% induction base. A (null-ary) Boolean function is a set of associations.
% An association maps an assignment for input arguments to one output value.
% True can be represented as $a \lor \neg a$ and false can be
% represented as $a \land \neg a$ for some free Boolean variable $a$ and using
% only negation, conjunctions and disjunctions. Recognize that those representations
% are given in DNF as well as CNF. Hence all null-ary Boolean functions can be
% represented as CNF and DNF.
%
% Let $f$ be a Boolean function represented in DNF with $k$ input arguments.
% Extend every conjunction with a Boolean variable $v_{k+1}$.
Consider the truth table of an arbitrary Boolean function $f$ with $k$ input arguments
and $j$ rows of output value false. We represent $f$ as CNF.

Consider Boolean variables $b_{i,l}$ with $0 \leq i \leq j$ and $0 \leq l \leq k$.
For every row $i$ of the truth table with assignment $(r_i)$, add one disjunction to the CNF.
This disjunction contains $b_{i,l}$ if $r_{i,l}$ is false.
The disjunction contains $b_{i,l}$ if $r_{i,l}$ is true.

As far as $f$ is an arbitrary $k$-ary Boolean function, we have proven that
any function can be represented as CNF.

SAT problems are usually represented in the DIMACS de-facto standard.
Consider a SAT problem in CNF with \emph{nbclauses} clauses and
enumerate all variables from 1 to \emph{nbvars}. A DIMACS file is an ASCII text
file. Lines starting with \enquote{\texttt{c}} are skipped (comment lines).
The first remaining line has to begin with \enquote{\texttt{p cnf}} followed by
\emph{nbclauses} and \emph{nbvars} separated by spaces (header line).
All following non-comment lines are space-separated indices of Boolean variables
optionally prefixed by a minus symbol. Then one line represents one clause and
must be terminated with a zero symbol after a space. All lines are conjuncted
to form a CNF.

Variations of the DIMACS de-facto standard also allow multiline clauses (the
zero symbol constitutes the end of a clause) or arbitrary whitespace instead of
spaces. The syntactical details are individually published on a per competition
basis.

\renewcommand{\lstlistingname}{Listing}  % TODO otherwise it's Japanese, WTF
\begin{lstlisting}[caption={Display~\ref{eq:xor} represented in DIMACS format}]
p cnf 2 2
a b
-a -b
\end{lstlisting}

\section{Terminology}
\label{sec:sat-terminology}
%
Given a conjunctive structure of disjunctions, we can define define terms
related to this structure:

\index{Clause}
\index{$k$-clause}
\index{Unit clause}
\index{Horn clause}
\index{Definite clause}
\begin{defi}
  A \emph{clause} is a disjunction of literals.
  A $k$-\emph{clause} is a clause consisting of exactly $k$ literals.
  A \emph{unit clause} is a $1$-clause.
  A \emph{Horn clause} is a clause with at most one positive literal.
  A \emph{definite clause} is a clause with exactly one positive literal.
  A \emph{goal clause} is a clause with no positive literal.
\end{defi}

\index{Negated literal}
\index{Existential literal}
\index{Used variable}
\begin{defi}
  Given a literal, its \emph{negated literal} is the literal with its sign negated.
  A literal is \emph{positive}, if its sign is positive. A literal is \emph{negative} if its sign is negative.
  An \emph{existential literal} is a literal which occurs exactly once and
  its negation does not occur. A \emph{used variable} is a variable which
  occurs at least once in the CNF.

  The \emph{literal frequency} is the number of occurences of a literal in the CNF divided by the number of clauses declared. Equivalently \emph{variable frequency} defines the number of variable occurences divided by the number of clauses declared.
\end{defi}

\index{Clause length}
\index{Tautological clause}
\begin{defi}
  The \emph{clause length of a clause} is the number of literals contained.
  A clause is called \emph{tautological} if a literal and its negated literal occurs in it.
\end{defi}

\section{Basic SAT solving techniques}
\label{sec:sat-solving}
%
\index{Equisatisfiability}
\begin{defi}
  Given two CNFs $A$ and $B$, they are called \emph{equisatisfiable} if and only
  if $A$ is satisfiable if and only if $B$.
\end{defi}

\subsection{Boolean constraint propagation (BCP)}
\label{sec:sat-bcp}
%
\index{Boolean constraint propagation}
One of the most basic techniques to SAT solving is \emph{Boolean Constraint Propagation},
also called \emph{unit propagation}.
It is so fundamental that SATzilla, introduced in Section~\ref{sec:features-related},
applies it immediately before looking at SAT features.

Let $l$ be the literal of a unit clause in a CNF. Remove any clause containing
$l$ and replace any occurences of $-l$ from the CNF. It is easy to see, that
the resulting CNF is equisatisfiable, because due to the unit clause $l$ must
be true. So any clause containing $l$ is satisfied and $-l$ yields false,
where $A \lor \bot$ is equivalent to $A$ for any Boolean function $A$.

\subsection{Watched literals}
\label{sec:sat-wl}
%
\index{Watched Literals}
Watched Literals are another fundamental concept in SAT solving. It is very
expensive to check satisfiability of all clauses for every value of a literal.
Watched Literals is a neat technique to reduce the number of checks.

Consider the solver assigns a value for literal $l$. Instead of looking at
all clauses and testing whether the clause is falsified by $l$, only clauses
containing $l$ are checked if $l$ is one of the watched literals of the clause.
This empirical approach was established with the Chaff and zChaff SAT solvers
and has proven useful in various variants.

\subsection{Remark}
\label{sec:sat-remark}
%
The previous two techniques shall illustrate basic approaches, but actual SAT
solving research requires decades of development to tune individual SAT solvers.
Memory models and concurrency strategies lead to fundamentally different runtime
behaviours of SAT solvers.

As such an initial idea to initiate an individual SAT solver specifically designed for
solving problems in differential cryptanalysis was dropped, because development time
is expected too long for a master thesis to be fruitful. As such we focused on popular
and established SAT solvers of the SAT community.

\section{SAT solvers in use}
\label{sec:sat-solvers}
%
\index{lingeling}
In this thesis we consider the several SAT solvers.
They have been selected either by their popularity
or their good results at previous SAT competitions:
\begin{itemize}
  \item MiniSat 2.2.0
  \item treengeling, lingeling and plingeling, in versions:
    \begin{itemize}
      \item lingeling ats1
      \item lingeling ats1o1
      \item lingeling ats1o2
      \item lingeling ats1o4
      \item lingeling baz
    \end{itemize}
  \item CryptoMiniSat 4.5
  \item CryptoMiniSat 5
  \item glucose syrup
\end{itemize}

Specifically this means the hash collision attacks we looked have run with
these SAT solvers. The results are discussed in Section~\ref{ch:results}
and provided in Appendix~\ref{app:runtimes}.

lingeling ats1o1, ats1o2 and ats1o4 are non-public releases of lingeling.
They have been developed in private communication with Armin Biere.
Our main goal was to achieve a separation between two sets of variables.
First all variables of the first need to be assigned in the best possible
way. Afterwards the second set of variables is considered.
Specifically variables modelling the differences between the two hash
algorithm instances should constitute the first set.

ats1o1 implements that difference variables are guessed with false first and
usual heuristics apply for all other variables.
Our intermediate results with incomplete CNF files showed a high number of restarts.
Therefore ats1o2 disables backjumping and therefore skips decisions for important variables.
Finally ats1o4 is not expected to distinguish from ats1o2. It only provides further debugging information.

The SAT solvers have generally been run without any special options, except for
\begin{itemize}
  \item MiniSat was run with \texttt{\textendash{}\textendash{}pre=once} as it is generally recommended to run with the builtin preprocessor.
  \item Lingeling has been generally run with \texttt{\textendash{}\textendash{}phase=-1} to prefer false as initial assignment to literals.
    However, lingeling ats1o1 implements this with more forceful strategy.
\end{itemize}

Preprocessing is a difficult topic on its own. Sometimes preprocessing can provide a speedup,
before actually solving the problem, but mostly SAT solvers implement preprocessing strategies
themselves and run them repeatedly when solving the problem.

TODO: testcases with lingeling have been run 5 times and mean was taken

TODO: glucose-syrup is glucose in many parallel threads
