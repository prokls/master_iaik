\renewcommand*\chappic{img/megosat.pdf}
\renewcommand*\chapquote{}
\renewcommand*\chapquotesrc{}
\chapter{Results}
\label{ch:results}
%
In Chapter~\ref{ch:sat}, we discussed Boolean algebra; in particular we looked at
satisfiability which is practically covered by SAT solvers. SAT solvers take
Boolean functions in Conjunctive Normal Form and determine satisfiability.
In Chapter~\ref{ch:dc}, we looked at how we can analyze algorithms by looking
at the progression of differences between algorithm instances. In particular,
we looked at hash algorithms introduced in Chapter~\ref{ch:hash}.

With this background we designed an attack setting in Chapter~\ref{ch:enc}
which enables us to verify and also find a hash collision given a differential
characteristic as starting point. Our goal is to find hash collisions
in practical time which we define by 1~day (86,400~seconds).
Therefore, we designed several approaches to improve our runtime results.

In this section, we will evaluate those approaches. Furthermore, we briefly
discuss claims we made about average SAT problems. In Section~\ref{ch:features},
we looked at SAT features which to some extent characterize a SAT problem.

\section{Evaluating SAT features}
\label{sec:results-features}
%
In Chapter~\ref{ch:features}, we posed 8 questions.
In the following, we want to answer them with the data
provided by the cnf-analysis project.

\begin{description}
\item[Given an arbitrary literal. What is the percentage it is positive?]
  We look at every clause and determine the ratio of positive to the total number of literals.
  We determine the mean per CNF file and the mean among all CNF files
  and retrieve a value of $0.48$ meaning that 48~\% of the literals are positive.
\item[What is the clauses / variables ratio?]
  In average a CNF file has 12,219 variables and 89,541 clauses.
  Its clauses-variables ratio is 7.328.
\item[How many literals occur only once either positive or negative?]
  In average there are 36 existential literals per CNF file,
  but its standard deviation of 967 is very large.
\item[What is the average and longest clause length among CNF benchmarks?]
  The average clause length is 3.04 with a standard deviation of 0.99
  and the longest clause length found was 61,473. Long clauses are typically
  outliers excluding specific assignments.
\item[How many Horn clauses exist in a CNF?]
  In average 29,994 goal clauses and 31,315 definite clauses exist
  with an average number of 83,649 clauses in a CNF file.
\item[Are there any tautological clauses?]
  In one file, 1679 tautological literals have been found. However,
  its mean is 0.07 with a standard deviation of $9.63$ meaning that tautological
  clauses are very rare.
\item[Are there any CNF files with more than one connected variable component?]
  Indeed, an average CNF file contains 67.07 connected variable components.
  However, its median is 1 implying that at least half of the CNF files
  have only 1 connected variable component.
\item[How many variables of a CNF are covered by unit clauses?]
  In average 124 variables are covered by unit clauses. This is an insignificant
  number compared to 12,219 variables in an average CNF.
\end{description}

The clauses/variables ratio was thoroughly studied by the SAT
community~\cite{nudelman2004understanding}.
A strong correlation between the instance's hardness and the ratio of number
of clauses to number of variables exists~\cite{selman1996generating}
though it is important to point out that this result holds for randomly
generated SAT instances, which our testcases are not classified as.

Existential literals are interesting to discover, because they allow
to remove a clause immediately. Consider a clause with literals
$(l_1, l_2, \ldots, l_n)$. If a guarantee exists such that the variable
of any literal $l_i$ does not occur in any other clause, we can claim
$l_i$ true rendering the clause satisfied.

Tautological clauses trivially also render clauses satisfied.

Connected variable components are interesting, because they split the
SAT problem into several small independent subproblems which can be 
solved in parallel.
Consider two sets of variables $A$ and $B$. Now consider some clauses
using only variables of $A$ and some clauses using only variables of $B$.
The overall CNF is satisfiable iff both clause sets are satisfiable.
The overall CNF is falsifiable iff any clause set is falsifiable.
Hence, if we know the connected variable components, we could easily
create two parallel SAT solver instances and solve the problems
independently. 4,607 out of 62,251 CNF files contained more than one
connected variable component.

These features represent very fundamental properties of the SAT problem.
But for us the question arises whether we can distinguish our cryptoproblems
from average problems?

\begin{itemize}
\item We looked at 36 files classified as cryptographic problems.
  They are considered cryptographic, because their file or folder name
  indicated they are related to hash functions or general cryptographic
  applications like AES. The specific selection can be identified by
  the crypto tag annotated to these CNF files as part of the cnf-analysis
  project.
\item In average these problems have 116,398 clauses and 27,407 variables.
  The average clauses-variables ratio is 5.58.
\item The 36 cryptographic SAT instances give a standard deviation of 0.7
  for clause length meaning that most clause lengths are close to
  the mean 3.4.
\item The number of definite clauses is twice its value for general problems
  (62,457 versus 31,315) and the number of goal clauses is 26~\% of its
  value for general problems (7,761 versus 29,994).
\item The number of connected variable components is 2,236 in average
  ($\sigma =$ 10,060), but the median is $1$ again.
\end{itemize}

No other value has been found to be significantly different from
average problems (or its difference follows immediately by the
non-uniform clause length).

The number of connected variable components seems interesting in
cryptographic problem, because it might indicate diffusion
in cryptographic problems. Diffusion means that variables strongly
interact with many different variables due to the repetitive
structure of cryptographic primitives. And finally the other
differences can be explained by a certain SAT design which
reoccurs in these testcases, because 36 is an exceptionally small
number compared to 62,251 unique CNF problems. It is expected
the cryptographic problems were designed by a small set of authors.

Comparing our average problem with cryptographic problems did
not draw any useful conclusions. Particularly a more thorough discussion
of the SAT designs might be more valuable than our high-level features.
We now specifically look at a SAT design we are familiar with:
Do average SAT problems distinguish from \emph{our} CNF testcases?

\begin{itemize}
  \item For all MD4 testcases we have the same number of variables,
    because the internal state of the hash algorithm instances are
    always the same size.
    However, adding the differential description as described in
    Section~\ref{sec:enc-diff-desc} increases the number of clauses
    by about 47~\% ($\sigma = 0.0005$) for MD4 instances and
    by about 43~\% ($\sigma = 0.0008$) for SHA-256 instances.
    For SHA-256 problems, this is illustrated in Table~\ref{tab:problem-sizes}.
    The preference variable introduced in Section~\ref{sec:enc-diff-desc-eo}
    increases the number of variables by about 80~\%
    and the number of clauses by factor 2.

    %\begin{table}[!h]
    %  \begin{center}
    %    \begin{tabular}{rc|rc}
    %      MD4~A: & 254,656 / 48,704 & MD4~A diff-desc: & 374,592 / 48,704 \\
    %      MD4~B: & 254,210 / 48,704 & MD4~B diff-desc: & 374,146 / 48,704 \\
    %      MD4~C: & 253,984 / 48,704 & MD4~C diff-desc: & 373,920 / 48,704 \\
    %      SHA-256 18: & 590,953 / 107,839 & SHA-256 18 diff-desc: & 846,487 / 107,839 \\
    %      SHA-256 21: & 636,838 / 116,800 & SHA-256 21 diff-desc: & 911,629 / 116,800 \\
    %      SHA-256 23: & 667,438 / 122,774 & SHA-256 23 diff-desc: & 955,067 / 122,774 \\
    %      SHA-256 24: & 682,722 / 125,761 & SHA-256 24 diff-desc: & 976,770 / 125,761
    %    \end{tabular}
    %    \caption{Our testcases and their number of clauses / variables}
    %  \end{center}
    %\end{table}

    Compared to 83,542 clauses and 12,219 variables for our average SAT problem,
    we consider our testcases to be noticeably large. However, it is important to
    point out that the problem size does not necessarily correlate with
    the hardness of the SAT problem.

  \item The variables of clauses of average SAT problems
    have a standard deviation of 3,337 in average ($\sigma=$1,261, median $=$3,643).
    Our average SAT problem has a standard deviation of 1,004 in average
    ($\sigma=$13,992, median $=22$). Hence variables which got created at every
    point during the CNF generation are shared within one clause.
    The general statement, that variable enumeration is arbitrary
    and therefore this standard deviation has no meaning holds, but we need
    to consider that practically speaking variables created close to each
    other share close variable indices.
    Under these assumptions a large $\sigma$ indicates variables are reused.
    We assume this is another indicator for high diffusion in cryptographic
    algorithms. Values are intermingled over and over throughout the repetitive
    structure of hash algorithms.

  \item Connected variables components are 129 for MD4 problems and 2 for SHA-256
    problems. For SHA-256 problems, a unit clause is given as existential literal
    and for MD4 problems, all components except one are of size 3.
    We did not investigate further, because this number is constant
    with an increasing problem size and all other variables are strongly
    correlated due to a high diffusion.

  \item An average literal frequency of $3.5\cdot 10^{-5}$ for our testcases
    is much lower than 0.014 for average problems. We explain this with the
    larger problem size. Literal frequency is divided by the number of clauses
    of the CNF and is therefore smaller, the larger the problem is.
\end{itemize}

In general we were not able to identify features allowing us to solve
differential cryptanalysis problems more efficiently compared to
general-purpose SAT problems. We concluded writing your own SAT solver
dedicated to solving differential cryptanalysis problems is not worth
the effort.

\section{Finding hash collisions}
\label{sec:results-attacks}
%
In this section, we look at our runtime results of testcases provided in
Appendix~\ref{app:tc}. We make various claims and substantiate them
with runtime results. Runtimes are always provided in seconds. Therefore
smaller runtimes are better. \timeout{} denotes a timeout (solving took
more than 1 day) and \unknown{} denotes unavailable data.

We considered MD4 testcases~A, B and C (listed in Table~\ref{tab:md4-tcs})
and generated the corresponding CNF files. The SAT solvers mentioned
in Section~\ref{sec:sat-solvers} were used to evaluate whether the problem
is solvable within the time limit.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{cccccc}
      \textbf{algorithm} & \textbf{testcase} & \textbf{rounds} & \textbf{diff. characteristic} & \textbf{clauses} & \textbf{variables} \\
    \hline
      MD4                & A                 & 48              & Appendix~\ref{fig:tcA}        & 254,656          & 48,704 \\
      MD4                & B                 & 48              & Appendix~\ref{fig:tcB}        & 254,210          & 48,704 \\
      MD4                & C                 & 48              & Appendix~\ref{fig:tcC}        & 253,984          & 48,704
    \end{tabular}
    \caption{MD4 testcases considered}
    \label{tab:md4-tcs}
  \end{center}
\end{table}

\subsection{Attacking MD4}
\label{sec:results-md4}
%
\begin{prop}
  Testcase~A in the encoding described in Section~\ref{sec:enc-original}
  can be solved within one minute by all considered SAT solvers.
\end{prop}

In our attack setting we started off with Testcase~A. It serves
rather as a toy example to verify correctness of our implementation than
as an actual benchmark. Be aware that invalid implementations either
result in unsatisfiability for satisfiable testcases or runtime results are
unexpected because the SAT solver could not take advantage of our SAT design
improvements. This particular testcase can be solved easily with all major
SAT solvers as can be seen in Table~\ref{tab:tcA-results}.

We end up with the result, that the hash collision given in Testcase~C
can be solved by the majority of modern SAT solvers. Of course the cryptanalyst
needs to figure out good starting points for the hash collision and encode them
in the differential characteristic, but this task is still considered practical,
because this task can be easily automated.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{cccccc}
      \textbf{solver} & \textbf{version} & \textbf{propagations} & \textbf{decisions} & \textbf{restarts} & \textbf{runtime} \\
    \hline
      MiniSat       & 2.2.0   & 3,813,726    & 250,759    & \unknown & 3 \\
      CryptoMiniSat & 4.5.3   & 140,000      & 2,441,566  & 539      & 26 \\
                    & 5       & 32,163,801   & 2,178,965  & 598      & 29 \\
      Lingeling     & ats1    & 6,586,770    & 436,621    & 980      & 23 \\
      Plingeling    & ats1    & 452,630,440  & 3,275,498  & \unknown & 88 \\
      Treengeling   & ats1    & 18,629,811   & 1,640,289  & \unknown & 64 \\
      Glucose       & 4.0     & 14,727,839   & 990,491    & 272      & 8 \\
      Glucose Syrup & 4.0     & 37,021,496   & 629,363    & 201      & 14 \\
    \end{tabular}
    \caption{Testcase~A can be solved within 1 minute by all SAT solvers}
    \label{tab:tcA-results}
  \end{center}
\end{table}

\subsection{Evaluating simplification}
\label{sec:results-simplification}
%
As a next approach, we looked at CNF simplifiers. Those simplifiers consume a
CNF file and transform the CNF file to an equisatisfiable CNF file.
Those simplified CNF files might be subject to performance improvements.

\begin{prop}
  Simplification reduces the problem size (number of variables and clauses).
\end{prop}

%Consider for example Testcase~18 (Appendix \ref{sec:tc18}) in the basic encoding
%introduced in Section~\ref{sec:enc-original}. Then simplification will reduce the problem
%size down by 57--77~\% of its original size (as illustrated in Table~\ref{tab:simpl-size}).
%We verified these data for all simplified files and got similar results.
%Therefore the claim holds considering the problem size gets reduced to
%approximately half of its size.
%
%\begin{table}[!h]
%  \begin{center}
%    \begin{tabular}{rcccc}
%      \textbf{simplification} & \textbf{variables} &/& \textbf{clauses} & \textbf{(variables left / clauses left)} \\
%    \hline
%                none &    590953 &/& 107839  & (100~\% / 100~\%) \\
%            satelite &    457972 &/& 69670   & (77.50~\% / 64.61~\%) \\
%               cmsat &    342139 &/& 61789   & (57.90~\% / 57.30~\%) \\
%           lingeling &    344544 &/& 107839  & (58.30~\% / 100.00~\%) \\
%             minisat &    391134 &/& 61845   & (66.19~\% / 57.35~\%)
%    \end{tabular}
%    \caption{
%        Problem sizes of Testcase 18 in the encoding of
%        Section~\ref{sec:enc-original} after simplification
%    }
%    \label{tab:simpl-size}
%  \end{center}
%\end{table}

Consider for example Testcase~C (Appendix \ref{sec:tcC}) in the basic encoding
introduced in Section~\ref{sec:enc-original}. Then simplification will reduce the problem
size down to 42.9~\% or more of its original size (as illustrated in Table~\ref{tab:simpl-size}).
We verified these data for all simplified files and got similar results.
Therefore the claim holds considering the problem size gets reduced to
approximately half of its size.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{rcccc}
      \textbf{simplification} & \textbf{variables} & \textbf{percent of none} &\textbf{clauses} & \textbf{percent of none} \\
    \hline
           none &    48,704 & 100~\%   & 253,984 & 100~\% \\
          cmsat &    24,503 & 50.31~\% & 111,931 & 44.07~\% \\
      lingeling &    48,704 & 100~\%   & 106,626 & 41.98~\% \\
        minisat &    20,895 & 42.90~\% & 118,236 & 46.55~\% \\
       satelite &    27,495 & 56.45~\% & 153,262 & 60.34~\%
    \end{tabular}
    \caption{
        Problem sizes of Testcase~C in the encoding of
        Section~\ref{sec:enc-original} after simplification.
        lingeling maintains the same number of variables
        according to the CNF header.
    }
    \label{tab:simpl-size}
  \end{center}
\end{table}

\begin{prop}
  Simplification as preprocessing step does not significantly improve the runtime of SAT solvers.
\end{prop}
%
We look at Testcase~C which is a more difficult MD4 problem
compared to Testcase~A. Simplification runtime results depend on the
SAT solver, which applies certain simplifications while trying to solve the
CNF, and the simplifier used. A small number of variables or clauses does
not necessarily lead to better performance. But an equisatisfiable encoding
of the same problem is worth considering.

Table~\ref{tab:simplification-results} lists runtimes depending
on the simplification used.

\begin{description}
\item[none]
  refers to the unsimplified CNF
\item[cmsat]
  refers to simplification applied with Cryptominisat version~5: \\
  \texttt{./cryptominisat5 -p1 file.cnf simplified.cnf}
\item[lingeling]
  refers to simplification with lingeling version ats1: \\
  \texttt{./lingeling -s file.cnf -o simplified.cnf}
\item[minisat]
  also simplifies CNF file with the following command line: \\
  \texttt{./minisat file.cnf -dimacs=simplified.cnf}
\item[satelite]
  is specifically designed to simplify CNF files: \\
  \texttt{./satelite file.cnf simplified.cnf}
\end{description}

It is worth pointing out that simplification time is not part of the runtime
listed. Simplification can take very long. Especially simplifications with
lingeling have sometimes taken several hours without result.

In conclusion, simplification leads to a slight improvement of the runtime,
but in general we cannot recommend simplifying every CNF file before running it.
Because technically speaking, SAT solvers internally apply simplification
algorithms on their own.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{cc|ccccc}
      \textbf{solver} & \textbf{version} & \textbf{none} & \textbf{cmsat} & \textbf{lingeling} & \textbf{minisat} & \textbf{satelite} \\
    \hline
      MiniSat       & 2.2.0              & 4,519    & 7,649    & 1,337    & 1,476    & 1,293 \\
      CryptoMiniSat & 4.5.3              & \unknown & \unknown & \unknown & \unknown & \unknown \\
                    & 5                  & 1,064    & 973      & 1,201    & 4,470    & 3,920 \\
      Lingeling     & ats1               & 1,492    & 906      & 356      & 860      & 1,297 \\
      Treengeling   & ats1               & 1,281    & 13,401   & 20,903   & 13,790   & 10,840 \\
      Plingeling    & ats1               & 2,310    & 1,232    & 955      & 1,384    & 2,030 \\
      Glucose       & 4.0                & \unknown & \unknown & \unknown & \unknown & \unknown \\
      Glucose Syrup & 4.0                & \unknown & \unknown & \unknown & \unknown & \unknown
    \end{tabular}
    % algotocnf_1.cnf
    %
    % not listed in runtime results folder contained:
    %    lingeling-ats1:   74.3 seconds, 49.2 MB
    %    treengeling-ats1:  1955 100% scheduled jobs  1281.49 seconds, 2468 MB
    %    cmsat5, ling-simplified 1.cnf:     c Total time               : 1201.19
    %    plingeling, ling-simplified 1.cnf:     c 954.7 seconds, 719.9 MB
    \caption{Runtimes of Testcase~C after CNF files have been simplified}
    \label{tab:simplification-results}
  \end{center}
\end{table}

\subsection{Attacking SHA-256}
\label{sec:result-diff-desc}
%
\index{Differential description}
While the basic approach works well for MD4, hash algorithm SHA-256 encompasses
a much larger state making the problem significantly more difficult for the SAT solver.
Consider Testcases 18, 21, 23 and 24. Those testcases describe
round-reduced hash collisions on SHA-256 (the testcase number gives
the number of rounds). Our next approach is called differential description
as originally described in Section~\ref{sec:enc-diff-desc}. 

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{cc|cc}
        \textbf{testcase} & \textbf{clauses / variables} & \textbf{testcase} & \textbf{clauses / variables} \\
      \hline
        18: & 590,953 / 107,839 & 18 diff-desc: & 846,487 / 107,839 \\
        21: & 636,838 / 116,800 & 21 diff-desc: & 911,629 / 116,800 \\
        23: & 667,438 / 122,774 & 23 diff-desc: & 955,067 / 122,774 \\
        24: & 682,722 / 125,761 & 24 diff-desc: & 976,770 / 125,761 \\
    \end{tabular}
    \caption{Problem sizes of our SHA-256 testcases (clauses / variables)}
    \label{tab:problem-sizes}
  \end{center}
\end{table}

\begin{prop}
  A differential description encoding (Section~\ref{sec:enc-diff-desc})
  improves the runtime compared to a missing differential description.
\end{prop}

To testing differential description, we looked at MD4's Testcase~C
and compared it with out SHA-256 testcases. Those testcases
are described in detail in Appendices~\ref{sec:tc18}, \ref{sec:tc21}
and \ref{sec:tc23}.

Recall that differential description explicitly encodes
how differences in arithmetic and bitwise operations propagate in the CNF.
We discussed \boolf{XOR} and \boolf{MAJ} in Section~\ref{sec:enc-diff-desc}.

The data corresponds to even larger testcases, namely a 27-rounds
variant we looked at, but did not list. This 27-rounds testcase
could not be solved in many cases within our time limit and
is therefore excluded from our lists.

We evaluated runtimes with and without differential description.
In Table~\ref{tab:diff-desc-results} we randomly picked SAT solvers
and we can clearly see a significant improvement of the runtimes.

We continued by trying to influence the guessing strategy to reflect
differential cryptanalysis, which generally use the assumption
that difference variables are assigned first. This strategy
requires customization of the SAT solver and therefore we
only considered lingeling, which was adapted for our purposes.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{c|cccc}
                        & \multicolumn{2}{c}{\textbf{CryptoMiniSat~5}} & \multicolumn{2}{c}{\textbf{lingeling-ats1}} \\
      \textbf{testcase} & \textbf{w/o dd} & \textbf{w/ dd} & \textbf{w/o dd} & \textbf{w/ dd} \\
    \hline
      MD4, C            &       1,064 &        231 &      798 &         53 \\
      SHA-256, 18       &          37 &         37 &       31 &        160 \\
      SHA-256, 21       &    \timeout &      7,855 &   28,621 &      5,513 \\
      SHA-256, 23       &    \timeout &     26,212 &   76,196 &      1,450 \\
      SHA-256, 24       &    \timeout &     37,194 &   78,017 &      1,235
    \end{tabular}
    % not contained in folder structure:
    % SHA256-18, lingeling-ats1, with dd
    %   1805652 decisions, 30042.1 decisions/sec
    %   188760 conflicts, 3140.6 conflicts/sec
    %   47432866 propagations, 0.8 megaprops/sec
    %   60.1 seconds, 79.4 MB
    % MD4-C, lingeling-ats1, w/o dd
    %   18835161 decisions, 12588.8 decisions/sec
    %   9364054 conflicts, 6258.6 conflicts/sec
    %   830017204 propagations, 0.6 megaprops/sec
    %   1496.2 seconds, 147.4 MB
    % MD4-C, lingeling-ats1, w/ dd
    %   1710883 decisions, 32432.6 decisions/sec
    %   333050 conflicts, 6313.5 conflicts/sec
    %   44484852 propagations, 0.8 megaprops/sec
    %   52.8 seconds, 31.1 MB
    \caption{
      Runtimes for various testcases with or without differential
      description with CryptoMiniSat and lingeling. Testcase~C
      has been added for reference.
    }
    \label{tab:diff-desc-results}
  \end{center}
\end{table}

\subsection{Modifying the guessing strategy}
\label{sec:results-guessing}
%
In differential cryptanalysis the general assumption is made that
differences should be guessed first. Once they are assigned, we
can look at the Boolean values in the two hash algorithm instances.
To model this behavior, we looked at options provided by SAT solvers.

\newcommand\mone[1][-1]{\texttt{-{}-phase=#1}}
\begin{prop}
  Lingeling option \mone{} improves its runtime for our testcases.
\end{prop}
%
Option \mone{} of lingeling is described as \enquote{default phase} set to
$-1$ (negative), $0$ (Jeroslow-Wang strategy~\cite{JeroslowWang})
or $1$ (positive). Per default a strategy engineered by
Jeroslow-Wang~\cite{JeroslowWang} is used, but considering
Claim~\ref{prop:false-first} at page~\pageref{prop:false-first}
we expect \mone{} to provide better runtime results.

Indeed our results consistently indicate a small improvement.
This can be recognized in Table~\ref{tab:phase-results}.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{c|cc cc cc cc}
      \textbf{testcase} & \multicolumn{2}{c}{18} & \multicolumn{2}{c}{21} & \multicolumn{2}{c}{23} & \multicolumn{2}{c}{24} \\
    \hline
      \textbf{phase}    &       0 &     -1 &       0 &     -1 &       0 &     -1 &       0 &     -1 \\
    \hline
      \textbf{runtime}  &      31 &     22 &  28,621 & 19,717 &  76,196 & 71,677 & 85,774  & 70,259 \\
    \end{tabular}
    \caption{lingeling-ats1 results for SHA-256 comparing \mone{} with \mone[0]{}}
    \label{tab:phase-results}
  \end{center}
\end{table}

\subsection{Evaluating the lightweight approach}
\label{sec:lightweight-results}
%
Though the results of \mone{} was recognizable, we wanted to push it further.
We got in contact with Armin Biere who provided us an extended lingeling implementation
which understands the notion of difference variables as a set of variables which needs
to be assigned first.

\begin{prop}
  Evaluating difference variables first and with Boolean value false improves the runtime.
\end{prop}
%
The lightweight approach mentioned in Section~\ref{sec:enc-lightweight}
evaluates difference variables first with Boolean value false,
but neglects the differential description.
This approach is justified by the assumption that a low number of differences,
leading to a sparse differential path, is more likely to cancel out differences
ending in a hash collision.

Table~\ref{tab:diff-first-false-results} reveals a nice improvement (the runtime
becomes 0.85~\%) of its original runtime in average.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{c|c|cccc}
      \textbf{testcase}                   & \textbf{C} & \textbf{18} & \textbf{21} & \textbf{23} & \textbf{24} \\
    \hline
      \textbf{basic approach}      (ats1) &        798 &          31 &      28,621 &      76,196 &      85,774 \\
      \textbf{diff-first-false}  (ats1o1) &        652 &          29 &      27,599 &      59,312 &      66,052
    \end{tabular}
    \caption[Difference variables first (with Boolean value false) results]{
      lingeling-ats1o1 and lingeling-ats1 results
      comparing a difference variables (with Boolean value false) first approach
      with the basic approach
    }
    \label{tab:diff-first-false-results}
  \end{center}
\end{table}

\subsection{Using preference variables}
\label{sec:preference-variables}
%
Our last approach uses \emph{preference variables} mentioned in
Section~\ref{sec:enc-diff-desc-eo}. Under the assumption that
preference variables $x^*$ and difference variables $\Delta x$
are assigned first, an additional clauses provides a decision tree
which assigns difference variables first and once they are all set,
values for the two hash algorithm instances are assigned.

\begin{prop}
  Adding preference variables lead to a performance improvement.
\end{prop}
%
Section~\ref{sec:enc-diff-desc-eo} introduces preference variables
which enforce the idea that difference variables are evaluated first.
Preference variables only add additional clauses, but do not provide
a runtime improvement per se. The larger number of variables and
clauses make the problem potentially harder.

However, evaluating them with false first makes sure that a low
number of differences is propagated. Otherwise the SAT solver would
spend much time in fruitless branches and the number of restarts
would be comparably high.

Given an assigned difference variable, differential description
ensures that the value is propagated quickly to other parts of
the equation system. This justifies why our encoding with preference
variables should be compared to an instance with differential
description and difference variables first.

Table~\ref{tab:pref-vars-results} shows a significant runtime improvement.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{c|ccc}
      \textbf{testcase}                                & \textbf{A} &  \textbf{B} &  \textbf{C} \\
    \hline
      \textbf{CNF with differential description}       &         11 &         133 &       155 \\
      \textbf{additionally with preference variables}  &          8 &          50 &        62 \\
    \end{tabular}
    \caption{
      lingeling-ats1o1 testcases comparing an approach
      with differential description with additional preference variables
    }
    \label{tab:pref-vars-results}
  \end{center}
\end{table}

\section{Summary}
\label{sec:results-summary}
%
In this section we looked at various improvements to improve the runtime, namely
\begin{enumerate}
  \item CNF simplification
  \item differential description
  \item Lingeling's \mone{} option
  \item Difference variables first with Boolean false
  \item Preference variables
\end{enumerate}
%
We evaluated these approaches with several SAT solvers and found significiant
runtime improvements. We successfully found hash collisions for MD4 and SHA-256.
