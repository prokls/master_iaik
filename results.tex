\renewcommand*\chappic{img/megosat.pdf}
\renewcommand*\chapquote{}
\renewcommand*\chapquotesrc{}
\chapter{Results}
\label{ch:results}
%
In Chapter~\ref{ch:sat} we discussed Boolean algebra; in particular we looked at
satisfiability which is practically covered by SAT solvers. SAT solvers take
Boolean functions in Conjunctive Normal Form and determine satisfiability.
In Chapter~\ref{ch:dc} we looked at how we can analyze algorithms by looking
at the progression of differences between algorithm instances. In particular
we looked at hash algorithms introduced in Chapter~\ref{ch:hash}.

With this background we designed a attack setting in Chapter~\ref{ch:enc}
which enables us to verify and also find a hash collision given a differential
characteristic given as starting point. Our goal is to find hash collisions
in as little time as possible. Therefore we introduced several approaches
in Section~\ref{sec:enc-algotocnf}.

In this section we will evaluate those approaches. Furthermore we briefly
discuss claims we made about average SAT problems. In Section~\ref{ch:features}
we looked at SAT features which to some extent characterize a SAT problem.

\section{Evaluating SAT features}
\label{sec:results-features}
%
In the introduction of Chapter~\ref{ch:features} we posed 8 questions.
In the following, we want to answer them with the data provided by the
cnf-analysis project.

\begin{description}
\item[Given an arbitrary literal. What is the percentage it is positive?]
  We look at every clause and determine the ratio of positive to the total number of literals.
  We determine the mean per CNF file and the mean among all CNF files
  and retrieve a value of $0.48$ meaning that 48~\% of the literals are positive.
\item[What is the clauses / variables ratio?]
  In average a CNF file has 12,219 variables and 89,541 clauses.
  Its clauses-variables ratio is 7.328.
\item[How many literals occur only once either positive or negative?]
  In average there are 36 existential literals per CNF file,
  but its standard deviation of 967 is very high.
\item[What is the average and longest clause length among CNF benchmarks?]
  The average clause length is 3.04 with a standard deviation of 0.99
  and the longest clause length found was 61,473. Long clauses are typically
  outliers excluding specific assignments.
\item[How many Horn clauses exist in a CNF?]
  In average 29,994 goal clauses and 31,315 definite clauses exist
  with an average number of 83649 clauses in a CNF file.
\item[Are there any tautological clauses?]
  In a file, 1679 tautological literals have been found. However,
  its mean is 0.07 with a standard deviation of $9.63$ meaning that tautological
  clauses are very rare.
\item[Are there any CNF files with more than one connected variable component?]
  Indeed, an average CNF file contains 67.07 connected variable components.
  However, its median is 1 anyway implying that at least half of the CNF files
  have only 1 connected variable component.
\item[How many variables of a CNF are covered by unit clauses?]
  In average 124 variables are covered by unit clauses. This is an insignificant
  number compared to 12,219 variables in an average CNF.
\end{description}

The clauses/variables ratio was thoroughly studied by the SAT
community~\cite{nudelman2004understanding}.
A strong correlation between the instance's hardness and the ratio of number
of clauses to number variables exists~\cite{selman1996generating}
though it is important to point out that this result holds for randomly
generated SAT instances, which our benchmarks are not classified as.

Existential literals are interesting to discover, because they allow
to remove a clause immediately. Consider a clause with literals
$(l_1, l_2, \ldots, l_n)$. If a guarantee exists such that the variable
of any literal $l_i$ does not occur in any other clause, we can claim
$l_i$ true rendering the clause satisfied.

Tautological clauses obviously also render clauses satisfied.

Connected variable components are interesting, because they split the
SAT problem into several small subproblems which can be independently.
Consider two sets of variables $A$ and $B$. Now consider some clauses
using only variables of $A$ and some clauses using only variables of $B$.
The overall CNF is satisfiable iff both clause sets are satisfiable.
The overall CNF is falsifiable iff any clause set is falsifiable.
Hence if we know the connected variable components, we could easily
create two parallel SAT solver instances and solve the problems
independently. 4,607 out of 62,251 CNF files contained more than 1
connected variable component.

These properties represent very fundamental properties of the SAT problem.
But for us the question arises whether we can distinguish our cryptoproblems
from average problems?

\begin{itemize}
\item We looked at 36 files classified as cryptographic problems.
  They are considered cryptographic, because their file or folder name
  indicated they are related to hash functions or general cryptographic
  applications like AES. The specific selection can be identified by
  the crypto tag annotated to these CNF files as part of the cnf-analysis
  project.
\item 62,533 clauses and 8,279 variables in average yield a variables-clauses
  ratio of 7.55.
\item The 36 cryptographic SAT instances give a standard deviation of 0
  for clause length meaning that all clauses had the same length.
\item Whereas the number of connected variable components has a mean
  of 52.73 ($\sigma = 1225$, median $= 1$) for general problems,
  Our cryptographic problems considered had a mean of 1 ($\sigma = 0$, median $= 1$).
\item The number of definite clauses is half its value for general problems
  (16,687 versus 32,787) and the number of goal clauses is 16~\% of its
  value for general problems (5,767 versus 35,094).
\end{itemize}

No other value has been found to be significantly different from
average problems (or its difference follows immediately by the
non-uniform clause length). The number of connected variable
components seems interesting because it might indicate diffusion
in cryptographic problems. Diffusion means that variables strongly
interact with many different variables due to the repetitive
structure of cryptographic primitives. And finally the other
differences can be explained by a certain SAT design which
reoccurs in this benchmarks, because 36 is an exceptionally small
number compared to 62,251 unique CNF problems.

Comparing our average problem with cryptographic problems did
not draw any useful conclusions. Particularly a more thorough discussion
of the SAT designs might be more valuable than our high-level features.
We now specificall look at a SAT design we are familiar with:
Do average SAT problems distinguish from \emph{our} CNF benchmarks?

\begin{itemize}
  \item For all MD4 testcases we have the same number of variables,
    because the internal state of the hash algorithm instances are
    always the same size.
    However, adding the differential description described in
    Section~\ref{sec:enc-diff-desc} increases the number of clauses
    by about 47~\% ($\sigma = 0.0005$) for MD4 instances and
    by about 43~\% ($\sigma = 0.0008$) for SHA-256 instances.
    The additional variable introduced in Section~\ref{sec:enc-diff-desc-eo}
    increases the number of variables by about 80~\%
    and the number of clauses by factor 2.

    \begin{table}[!h]
      \begin{center}
        \begin{tabular}{rc|rc}
          MD4~C & 253,984 / 48,704 & MD4~C diff-desc & 373,920 / 48,704 \\
          MD4~B & 254,210 / 48,704 & MD4~B diff-desc & 374,146 / 48,704 \\
          MD4~A & 254,656 / 48,704 & MD4~A diff-desc & 374,592 / 48,704 \\
          SHA-256 18 & 590,953 / 107,839 & SHA-256 18 diff-desc & 846,487 / 107,839 \\
          SHA-256 21 & 636,838 / 116,800 & SHA-256 21 diff-desc & 911,629 / 116,800 \\
          SHA-256 23 & 667,438 / 122,774 & SHA-256 23 diff-desc & 955,067 / 122,774 \\
          SHA-256 24 & 682,722 / 125,761 & SHA-256 24 diff-desc & 976,770 / 125,761
        \end{tabular}
        \caption{Our testcases and their number of clauses / variables}
      \end{center}
    \end{table}

    Compared to 83,542 clauses and 12,219 variables for our average SAT problem,
    we consider our benchmark to be noticeably large. It is important to
    point out that the problem size does not necessarily correlate with
    the hardness of the SAT problem.

  \item The variables of clauses of average SAT problems
    have a standard deviation of 3,337 in average ($\sigma=$1,261, median $=$3,643).
    Our average SAT problem has a standard deviation of 1,004 in average
    ($\sigma=$13,992, median $=22$). Hence variables which got created at very
    points during the CNF generation are shared within one clause.
    The general statement, that variable enumeration is arbitrary
    and therefore this standard deviation has no meaning, holds but we need
    to consider that practically speaking variables created close to each
    other share close variable indices.
    Under these assumptions a large $\sigma$ indicates variables are reused.
    We assume this is another indicator for high diffusion in cryptographic
    algorithms. Values are intermingled over and over throughout the repetitive
    structure of hash algorithms.

  \item Connected variables components are 129 for MD4 problems and 2 for SHA-256
    problems. We couldn't explain where those components come from and the
    component size would help us to identify their source. We did not investigate
    further, because this number is constant with an increasing problem size.

  \item An average literal frequency of $3.5\cdot 10^{-5}$ for our benchmarks
    is much lower than 0.014 for average problems. We explain this with the
    larger problem size. Literal frequency is divided by the number of clauses
    of the CNF and is therefore smaller the larger the problem is.
\end{itemize}

In general we were not able to identify features which allows us to solve
differential cryptanalysis problems more efficiently compared to
general-purpose SAT problems. We concluded writing your own SAT solver
dedicated to solving differential cryptanalysis problems is not worth
the effort.

\section{Finding hash collisions}
\label{sec:results-attacks}

In this section we look at our benchmark results of Testcases provided in
Appendix~\ref{app:tc}. We make various propositions and substantiate them
with runtime results. Runtimes are always provided in seconds and \timeout{}
denotes a timeout (solving takes more than 1 day).

% We considered MD4 testcases~A, B and C (compare with Appendices~\ref{fig:tcA}, \ref{fig:tcB} and \ref{fig:tcC})
% and generated the corresponding CNF files. The SAT solvers mentioned in Section~\ref{sec:sat-solvers}
% were used to evaluate whether the problem is solvable in reasonably time. For every testcase we
% defined a time limit of at most 1 day (i.e. 86,400 seconds). A timeout is denoted by \timeout.
% Some testcases listed have been evaluated for a larger time limit.

\subsection{Attacking MD4}
\label{sec:results-md4}
%
\begin{prop}
  Testcase~\ref{sec:tcA} in the encoding described in Section~\ref{sec:enc-original}
  can be solved within one minute by all considered SAT solvers.
\end{prop}

In our attack setting we started off with Testcase~\ref{sec:tcA}. It serves
rather as a toy example to verify correctness of our implementation than
as an actual runtime benchmark. Be aware that invalid implementations either
result in unsatisfiability for satisfiable testcases or runtime results are
unexpected because the SAT solver could not take advantage of our SAT design
implementations. This particular testcase can be solved easily with all major
SAT solvers as can be seen in Table~\ref{tab:tcA-results}.

We end up with the result, that the hash collision given in Table~\ref{fig:tcC}
can be solved by a limited set of modern SAT solvers. Of course the cryptanalyst
needs to figure out good starting points for the hash collision and encode them
in the differential characteristic, but this task is still considered practical,
because this task can be easily automated.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{cccccc}
      \textbf{solver} & \textbf{version} & \textbf{propagations} & \textbf{decisions} & \textbf{restarts} & \textbf{runtime} \\
    \hline
      MiniSat       & 2.2.0   & 3,813,726    & 250,759   & \unknown & 3 \\
      CryptoMiniSat & 4.5.3   & 140,000      & 2,441,566 & 539      & 26 \\
                    & 5       & \unknown     & 2,428,824 & 637      & 37 \\
      Lingeling     & ats1    & 6,586,770    & 436,621   & 980      & 23 \\
      plingeling    & ats1    & 452,630,440  & 3,275,498 & \unknown & 88 \\
      Glucose       & 4.0     & 14,727,839   & 990,491   & 272      & 8 \\
      Glucose Syrup & 4.0     & \unknown     & 629,363   & 201      & 14 \\
    \end{tabular}
    % TODO: treengeling?
    \caption{Testcase~\ref{sec:tcA} can be solved within 1 minute by all SAT solvers}
    \label{tab:tcA-results}
  \end{center}
\end{table}

\subsection{Evaluating simplification}
\label{sec:results-simplification}
%
As a next approach, we looked at CNF simplifiers. Those simplifiers consume a
CNF file and transform the CNF file to an equisatisfiable CNF file.

\begin{prop}
  Simplification reduces the problem size (number of variables and clauses).
\end{prop}

Consider for example Testcase~\ref{sec:tc18} in the basic encoding introduced
in Section~\ref{sec:enc-original}. Then simplification will reduce the problem
size down by 57--77~\% of its original size (compare with Table~\ref{tab:simpl-size}).
We verified these data for all simplified files and got similar results.
Therefore the proposition holds considering the problem size gets reduced to
approximately half of its size.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{rcccc}
      \textbf{simplification} & \textbf{variables} &/& \textbf{clauses} & \textbf{(variables left / clauses left)} \\
    \hline
                none &    590953 &/& 107839  & (100~\% / 100~\%) \\
            satelite &    457972 &/& 69670   & (77.50~\% / 64.61~\%) \\
               cmsat &    342139 &/& 61789   & (57.90~\% / 57.30~\%) \\
           lingeling &    344544 &/& 107839  & (58.30~\% / 100.00~\%) \\
             minisat &    391134 &/& 61845   & (66.19~\% / 57.35~\%)
    \end{tabular}
    \caption{
        Problem sizes of Testcase~\ref{sec:tc18} in the encoding of
        Section~\ref{sec:enc-original} after simplification
    }
    \label{tab:simpl-size}
  \end{center}
\end{table}

\begin{prop}
  Simplification as preprocessing step does not significantly improve the runtime of SAT solvers.
\end{prop}
%
We look at Testcase~\ref{sec:tcC} which is a more difficult MD4 problem
compared to Testcase~\ref{sec:tcA}. Simplification runtime results depend on the
SAT solver, which applies certain simplifications while trying to solve the
CNF, and the simplifier used. Table~\ref{tab:simplification-results}
lists runtimes depending on the simplification used.

\begin{description}
\item[none] refers to the unsimplified CNF
\item[cmsat] refers to simplification applied with Cryptominisat version~5: \texttt{./cryptominisat5 -p1 file.cnf simplified.cnf}
\item[lingeling] refers to simplification with lingeling version ats1: \texttt{./lingeling -s file.cnf -o simplified.cnf}
\item[minisat] also simplifies CNF file with the following command line: \texttt{./minisat file.cnf -dimacs=simplified.cnf}
\item[satelite] is specifically designed to simplify CNF files: \texttt{./satelite file.cnf simplified.cnf}
\end{description}

It is worth pointing out that simplification time is not part of the listed
runtime. Simplification can take very long. Especially simplifications with
lingeling have sometimes taken several hours without result.

In conclusion, simplification leads to a slight improvement of the runtime,
but in general we cannot recommend simplifying every CNF file before running it.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{cc|ccccc}
      \textbf{solver} & \textbf{version} & \textbf{none} & \textbf{cmsat} & \textbf{lingeling} & \textbf{minisat} & \textbf{satelite} \\
    \hline
      MiniSat       & 2.2.0              & 4,519    & 7,649    & \unknown & 1,476 & 1,293 \\
      CryptoMiniSat & 4.5.3              & \unknown & \unknown & \unknown & \unknown & \unknown \\
                    & 5                  & 1,064    & 973      & \unknown & 4,470    & 3,920 \\
      Lingeling     & ats1               & 1,492    & 906      & \unknown & 860      & 1,297 \\
      Treengeling   & ats1               & 1,281    & 13,401   & \unknown & 13,790   & 10,840 \\
      plingeling    & ats1               & 2,310    & 1,232    & \unknown & 1,384    & 2,030 \\
      Glucose       & 4.0                & \unknown & \unknown & \unknown & \unknown & \unknown \\
      Glucose Syrup & 4.0                & \unknown & \unknown & \unknown & \unknown & \unknown
    \end{tabular}
    % algotocnf_1.cnf
    %
    % not listed in runtime results folder contained:
    %    lingeling-ats1:   74.3 seconds, 49.2 MB
    %    treengeling-ats1:  1955 100% scheduled jobs  1281.49 seconds, 2468 MB
    \caption{Runtimes of Testcase~\ref{sec:tcC} after CNF files have been simplified}
    \label{tab:simplification-results}
  \end{center}
\end{table}

\subsection{Improvements with differential description}
\label{sec:result-diff-desc}
%
Our next goal was to scale up to a more difficult problem. We considered SHA-256
which has a much larger internal state (at least by factor 2). So finding a hash
collision is more difficult and we considered further strategies.

\begin{prop}
  A differential description encoding (Section~\ref{sec:enc-diff-desc})
  improves the runtime compared to a missing differential description.
\end{prop}

Consider testcase~C for MD4 (Appendix~\ref{sec:tcA}) and testcases
testcases~18, 21 and 23 (Appendices~\ref{sec:tc18}, \ref{sec:tc21} and
\ref{sec:tc23}) for SHA-256. We evaluate the
runtimes with or without differential description.

Recall that differential description explicitly encode in the CNF
how differences in arithmetic and bitwise operations propagate.
We discussed \boolf{XOR} and \boolf{MAJ} in Section~\ref{sec:enc-diff-desc}.

The data corresponds to even larger testcases, namely a 27-rounds
variant we looked at, but did not list. This 27-rounds testcase
could not be solved in many cases within our time limit and
is therefore excluded from our lists.

In Table~\ref{tab:diff-desc-results} we randomly picked SAT solvers
and we can clearly see a significant improvement of the runtimes.

We continued by trying the influence the guessing strategy.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{c|cccc}
                        & \multicolumn{2}{c}{\textbf{CryptoMiniSat~5}} & \multicolumn{2}{c}{\textbf{lingeling-ats1}} \\
      \textbf{testcase} & \textbf{w/o dd} & \textbf{w/ dd} & \textbf{w/o dd} & \textbf{w/ dd} \\
    \hline
      MD4, C            &       1,064 &        231 &      798 &   \unknown \\
      SHA-256, 18       &          37 &         37 &       31 &        160 \\
      SHA-256, 21       &    \unknown &      7,855 &   28,621 &      5,513 \\
      SHA-256, 23       &    \unknown &     26,212 &   76,196 &      1,450
    \end{tabular}
    \caption{Runtimes for various testcases with or without differential description with CryptoMiniSat and lingeling}
    \label{tab:diff-desc-results}
  \end{center}
\end{table}

\subsection{Modifying the guessing strategy}
\label{sec:results-guessing}
%
\newcommand\mone[1][-1]{\texttt{\textendash{}\,\textendash{}phase=#1}}
\begin{prop}
  Using \mone{} improves the runtime of lingeling for our testcases.
\end{prop}
%
Option \mone{} of lingeling is described as default phase set to
$-1$ (negative), $0$ (Jeroslow-Wang strategy~\cite{JeroslowWang})
or $1$ (positive). Per default a strategy engineered by
Jeroslow-Wang~\cite{JeroslowWang} is used, but considering
Proposition~\ref{prop:false-first} at page~\pageref{prop:false-first}
we expect \mone{} to provide better runtime results.

Indeed our results consistently indicate a small improvement.
This can be recognized in Table~\ref{tab:phase-results}.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{c|cc cc cc cc}
      \textbf{testcase} & \multicolumn{2}{c}{18} & \multicolumn{2}{c}{21} & \multicolumn{2}{c}{23} & \multicolumn{2}{c}{24} \\
    \hline
      \textbf{phase}    &       0 &      1 &       0 &      1 &       0 &      1 &       0 &      1 \\
    \hline
      \textbf{runtime}  &      31 &     22 &  28,621 & 19,717 &  76,196 & 71,677 &  85774  & 70,259 \\
    \end{tabular}
    \caption{lingeling-ats1 results for SHA-256 comparing \mone{} with \mone[0]{}}
    \label{tab:phase-results}
  \end{center}
\end{table}





As pointed out in Section~\ref{sec:enc-diff-desc-ocnf}, a best practice law of
differential cryptanalysis states that difference variables should be
assigned first. Afterwards propagation of actual values for the two
instances can take place.

To enforce such a strategy, we tried several approaches:
\begin{enumerate}
  \item
    Armin Biere provided us with a custom release of lingeling
    which enforces that a special set of variables is evaluated
    first. It is important that the CNF is still solved
    with usual SAT solver heuristics, because enforcing
    assignment of one variable after another leads to an increase
    in backtracking steps and restarts. Hence, we consider this
    release as a nice tradeoff. Difference variables are assigned
    \enquote{as early as possible, as late as necessary}.
  \item
    Given this custom SAT solver we considered a SAT design which
    requires the SAT solver to prefer a certain. This particular
    design with a special Boolean variable is explained in
    Section~\ref{sec:enc-diff-desc-eo}.
\end{enumerate}

\section{Related work}
\label{sec:results-related}
%
In my bachelor thesis~\cite{bach} we tried to integrate a SAT solver into
our department's existing tool which encodes propagation explicitly. This approach
was not very successful as restarts between hash algorithm rounds implied that
intermediate results by the SAT solver get lost.

Research was already done by Ilya Mironov and Lintao Zhang~\cite{mironov2006applications}
to apply SAT solvers to differential cryptanalysis specifically to find hash collision
in MD4. However whereas their basic approach seems to correspond to our approach described
in Section~\ref{sec:enc-original}, our implementation uses additional SAT design tweaks
to improve our results. Also because 10 years have gone since publication, SAT technology
has progressed and modern SAT solvers on modern hardware provide better results.



TODO justify: differential description improves runtime


\section{Conclusion}
\label{sec:conclusion}
%
We successfully found full-round hash collisions for MD4
using SAT solvers mentioned in Section~\ref{sec:sat-solvers}.
We applied tweaks to the lingeling SAT solver to improve our
runtime results further and found 24-round hash collisions
for SHA-256. Our attack starting points for MD4 ---
Testcases~\ref{fig:tcA}, \ref{fig:tcB} and \ref{fig:tcC} ---
were found by Yusuke Naito, Yu Sasaki, Noboru Kunihiro and
Kazuo Ohta~\cite{sasaki2007new}. Our starting points for SHA-256
--- Testcases~\ref{fig:tc18}, \ref{fig:tc21}, \ref{fig:tc23}
and \ref{fig:tc24} --- were found by Ivica Nikoli{\'c} and
Alex Biryukov~\cite{nikolic2008collisions}.

\section{Contributions}
\label{sec:contributions}
%
To strengthen Reproducible Research, the source code and data resulting from this thesis is available online.
It allows the reader to run the experiments again and verify our claims.
We did our best to describe our hardware setup as accurately as possible.
At the following website, any results part of this project are collected:

\begin{quote}
  \url{http://lukas-prokop.at/proj/megosat/}
\end{quote}

Several subprojects are part of this master thesis:
\begin{description}
\item[algotocnf]\hfill{} \\
  A python library implementing the encoding described in Chapter~\ref{ch:enc}. \\[4pt]
  \textbf{Python3 library and program:} \url{https://github.com/prokls/algotocnf}
\item[cnf-hash]\hfill{} \\
  A standardized way to produce a unique hash for CNF files \\[4pt]
  \textbf{Go implementation:} \url{https://github.com/prokls/cnf-hash-go} \\
  \textbf{Python3 implementation:} \url{https://github.com/prokls/cnf-hash-py} \\
  \textbf{Testsuite:} \url{https://github.com/prokls/cnf-hash-tests2}
\item[cnf-analysis]\hfill{} \\
  Evaluate SAT features for a given CNF file. \\[4pt]
  \textbf{Go implementation:} \url{https://github.com/prokls/cnf-analysis-go} \\
  \textbf{Python3 implementation:} \url{https://github.com/prokls/cnf-analysis-py} \\
  \textbf{Testsuite:} \url{https://github.com/prokls/cnf-analysis-tests}
\end{description}
