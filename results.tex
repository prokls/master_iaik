\renewcommand*\chappic{img/megosat.pdf}
\renewcommand*\chapquote{}
\renewcommand*\chapquotesrc{}
\chapter{Results}
\label{ch:results}
%
In Chapter~\ref{ch:sat} we discussed Boolean algebra; in particular we looked at
satisfiability which is practically covered by SAT solvers. SAT solvers take
Boolean functions in Conjunctive Normal Form and determine satisfiability.
In Chapter~\ref{ch:dc} we looked at how we can analyze algorithms by looking
at the progression of differences between algorithm instances. In particular
we looked at hash algorithms introduced in Chapter~\ref{ch:hash}.

With this background we designed a attack setting in Chapter~\ref{ch:enc}
which enables us to verify and also find a hash collision given a differential
characteristic given as starting point. Our goal is to find hash collisions
in as little time as possible. Therefore we introduced several approaches
in Section~\ref{sec:enc-algotocnf}.

In this section we will evaluate those approaches. Furthermore we briefly
discuss claims we made about average SAT problems. In Section~\ref{ch:features}
we looked at SAT features which to some extent characterize a SAT problem.

\section{Evaluating SAT features}
\label{sec:results-features}
%
In the introduction of Chapter~\ref{ch:features} we posed 8 questions.
In the following, we want to answer them with the data provided by the
cnf-analysis project.

\begin{description}
\item[Given an arbitrary literal. What is the percentage it is positive?]
  We look at every clause and determine the ratio of positive to the total number of literals.
  We determine the mean per CNF file and the mean among all CNF files
  and retrieve a value of $0.48$ meaning that 48~\% of the literals are positive.
\item[What is the clauses / variables ratio?]
  In average a CNF file has 12,219 variables and 89,541 clauses.
  Its clauses-variables ratio is 7.328.
\item[How many literals occur only once either positive or negative?]
  In average there are 36 existential literals per CNF file,
  but its standard deviation of 967 is very high.
\item[What is the average and longest clause length among CNF benchmarks?]
  The average clause length is 3.04 with a standard deviation of 0.99
  and the longest clause length found was 61,473. Long clauses are typically
  outliers excluding specific assignments.
\item[How many Horn clauses exist in a CNF?]
  In average 29,994 goal clauses and 31,315 definite clauses exist
  with an average number of 83649 clauses in a CNF file.
\item[Are there any tautological clauses?]
  In a file, 1679 tautological literals have been found. However,
  its mean is 0.07 with a standard deviation of $9.63$ meaning that tautological
  clauses are very rare.
\item[Are there any CNF files with more than one connected variable component?]
  Indeed, an average CNF file contains 67.07 connected variable components.
  However, its median is 1 anyway implying that at least half of the CNF files
  have only 1 connected variable component.
\item[How many variables of a CNF are covered by unit clauses?]
  In average 124 variables are covered by unit clauses. This is an insignificant
  number compared to 12,219 variables in an average CNF.
\end{description}

The clauses/variables ratio was thoroughly studied by the SAT
community~\cite{nudelman2004understanding}.
A strong correlation between the instance's hardness and the ratio of number
of clauses to number variables exists~\cite{selman1996generating}
though it is important to point out that this result holds for randomly
generated SAT instances, which our benchmarks are not classified as.

Existential literals are interesting to discover, because they allow
to remove a clause immediately. Consider a clause with literals
$(l_1, l_2, \ldots, l_n)$. If a guarantee exists such that the variable
of any literal $l_i$ does not occur in any other clause, we can claim
$l_i$ true rendering the clause satisfied.

Tautological clauses obviously also render clauses satisfied.

Connected variable components are interesting, because they split the
SAT problem into several small subproblems which can be independently.
Consider two sets of variables $A$ and $B$. Now consider some clauses
using only variables of $A$ and some clauses using only variables of $B$.
The overall CNF is satisfiable iff both clause sets are satisfiable.
The overall CNF is falsifiable iff any clause set is falsifiable.
Hence if we know the connected variable components, we could easily
create two parallel SAT solver instances and solve the problems
independently.

These properties represent very fundamental properties of the SAT problem.
But for us the question arises whether we can distinguish our cryptoproblems
from average problems?

\begin{itemize}
\item We looked at 36 files classified as cryptographic problems.
  They are considered cryptographic, because their file or folder name
  indicated they are related to hash functions or general cryptographic
  applications like AES. The specific selection can be identified by
  the crypto tag annotated to these CNF files as part of the cnf-analysis
  project.
\item 62,533 clauses and 8,279 variables in average yield a variables-clauses
  ratio of 7.55.
\item The 36 cryptographic SAT instances give a standard deviation of 0
  for clause length meaning that all clauses had the same length.
\item Whereas the number of connected variable components has a mean
  of 52.73 ($\sigma = 1225$, median $= 1$) for general problems,
  Our cryptographic problems considered had a mean of 1 ($\sigma = 0$, median $= 1$).
\item The number of definite clauses is half its value for general problems
  (16,687 versus 32,787) and the number of goal clauses is 16~\% of its
  value for general problems (5,767 versus 35,094).
\end{itemize}

No other value has been found to be significantly different from
average problems (or its difference follows immediately by the
non-uniform clause length). The number of connected variable
components seems interesting because it might indicate diffusion
in cryptographic problems. Diffusion means that variables strongly
interact with many different variables due to the repetitive
structure of cryptographic primitives. And finally the other
differences can be explained by a certain SAT design which
reoccurs in this benchmarks, because 36 is an exceptionally small
number compared to 62,251 unique CNF problems.

Comparing our average problem with cryptographic problems did
not draw any useful conclusions. Particularly a more thorough discussion
of the SAT designs might be more valuable than our high-level features.
We now specificall look at a SAT design we are familiar with:
Do average SAT problems distinguish from \emph{our} CNF benchmarks?

\begin{itemize}
  \item For all MD4 testcases we have the same number of variables,
    because the internal state of the hash algorithm instances are
    always the same size.
    However, adding the differential description described in
    Section~\ref{sec:enc-diff-desc} increases the number of clauses
    by about 47~\% ($\sigma = 0.0005$) for MD4 instances and
    by about 43~\% ($\sigma = 0.0008$) for SHA-256 instances.
    The additional variable introduced in Section~\ref{sec:enc-diff-desc-eo}
    increases the number of variables by about 80~\%
    and the number of clauses by factor 2.

    \begin{table}[!h]
      \begin{center}
        \begin{tabular}{rc|rc}
          MD4~C & 253,984 / 48,704 & MD4~C diff-desc & 373,920 / 48,704 \\
          MD4~B & 254,210 / 48,704 & MD4~B diff-desc & 374,146 / 48,704 \\
          MD4~A & 254,656 / 48,704 & MD4~A diff-desc & 374,592 / 48,704 \\
          SHA-256 18 & 590,953 / 107,839 & SHA-256 18 diff-desc & 846,487 / 107,839 \\
          SHA-256 21 & 636,838 / 116,800 & SHA-256 21 diff-desc & 911,629 / 116,800 \\
          SHA-256 23 & 667,438 / 122,774 & SHA-256 23 diff-desc & 955,067 / 122,774 \\
          SHA-256 24 & 682,722 / 125,761 & SHA-256 24 diff-desc & 976,770 / 125,761
        \end{tabular}
        \caption{Our testcases and their number of clauses / variables}
      \end{center}
    \end{table}

    Compared to 83,542 clauses and 12,219 variables for our average SAT problem,
    we consider our benchmark to be noticeably large. It is important to
    point out that the problem size does not necessarily correlate with
    the hardness of the SAT problem.
\end{itemize}

TODO extend statistics (e.g. simplification)

In general we were not able to identify features which would justify to
write our own SAT solver dedicated to solving differential cryptanalysis problems.

\section{Finding hash collisions}
\label{sec:results-attacks}

In this section we look at our benchmark results of Testcases provided in
Appendix~\ref{app:tc}.

\subsection{Attacking MD4}
\label{sec:results-md4}
%
In our attack setting we started off with Testcase~\ref{sec:tcA}. It serves
rather as a verification example to test our encoding is modelled correctly
(an invalid encoding is expected to result in unsatisfiability). This particular
testcase can be solved easily with all major SAT solvers as can be seen in
Table~\ref{tab:tcA-results}.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{cc}
      data & missing
    \end{tabular}
    \caption{Runtimes of testcase~\ref{sec:tcA}}
  \end{center}
\end{table}

In the following, we make various propositions and support with the runtime results:

\begin{prop}
  Simplification as preprocessing step does not significantly improve the runtime of SAT solvers.
\end{prop}

\begin{prop}
  Using \texttt{\textendash{}\textendash{}phase=-1} does not significantly
  improve the runtime of lingeling
\end{prop}


TODO: is simplification worth it?

Appendix~\ref{app:runtimes} provide a more exhaustive list of runtimes retrieved.

In Section~\ref{sec:enc-algotocnf} we introduced a basic encoding involving two hash algorithm
instances and difference variables. Constraints resulting from the hash algorithm description
and given differential characteristic are added.

We considered MD4 testcases~A, B and C (compare with Appendices~\ref{fig:tcA}, \ref{fig:tcB} and \ref{fig:tcC})
and generated the corresponding CNF files. The SAT solvers mentioned in Section~\ref{sec:sat-solvers}
were used to evaluate whether the problem is solvable in reasonably time. For every testcase we
defined a time limit of at most 1 day (i.e. 86,400 seconds). A timeout is denoted by \timeout.
Some testcases listed have been evaluated for a larger time limit.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{lcc}
      SAT solver                & testcase      & runtime (in seconds) \\
    \hline
      minisat~2.2.0             & MD4, A        & 65 \\
      cryptominisat~4.5.3       & MD4, A        & 24 \\
      cryptominisat~5.0.0       & MD4, A        & 29 \\
      glucose~4.0               & MD4, A        & 10 \\
      glucose-syrup~4.0         & MD4, A        & 31 \\
      lingeling-ats1            & MD4, A        & TODO \\
      lingeling-ats1o1          & MD4, A        & 18 \\
      lingeling-ats1o2          & MD4, A        & TODO \\
      lingeling-ats1o4          & MD4, A        & 125,745 \\
      plingeling-ats1o1         & MD4, A        & 88 \\
      treeneling-ats1o1         & MD4, A        & 64
    \end{tabular}
    \caption{Runtimes for MD4 testcase A with various SAT solvers}
    \label{tab:md4-A-runtimes}
  \end{center}
  \begin{center}
    \begin{tabular}{lcc}
      SAT solver                & testcase      & runtime (in seconds) \\
    \hline
      minisat~2.2.0             & MD4, B        & 7,817 \\
      cryptominisat~4.5.3       & MD4, B        & \timeout \\
      cryptominisat~5.0.0       & MD4, B        & 571 \\
      glucose~4.0               & MD4, B        & \timeout \\
      glucose-syrup~4.0         & MD4, B        & \timeout \\
      lingeling-ats1            & MD4, B        & TODO \\
      lingeling-ats1o1          & MD4, B        & 257 \\
      lingeling-ats1o2          & MD4, B        & TODO \\
      lingeling-ats1o4          & MD4, B        & TODO \\
      plingeling-ats1o1         & MD4, B        & 1,860 \\
      treeneling-ats1o1         & MD4, B        & 12,574
    \end{tabular}
    \caption{Runtimes for MD4 testcase B with various SAT solvers}
    \label{tab:md4-B-runtimes}
  \end{center}
  \begin{center}
    \begin{tabular}{lcc}
      SAT solver                & testcase      & runtime (in seconds) \\
    \hline
      minisat~2.2.0             & MD4, C        & 19,683 \\
      cryptominisat~4.5.3       & MD4, C        & \timeout \\
      cryptominisat~5.0.0       & MD4, C        & 1064 \\
      glucose~4.0               & MD4, C        & \timeout \\
      glucose-syrup~4.0         & MD4, C        & \timeout \\
      lingeling-ats1            & MD4, C        & TODO \\
      lingeling-ats1o1          & MD4, C        & TODO \\
      lingeling-ats1o2          & MD4, C        & TODO \\
      lingeling-ats1o4          & MD4, C        & TODO \\
      plingeling-ats1o1         & MD4, C        & TODO \\
      treeneling-ats1o1         & MD4, C        & TODO
    \end{tabular}
    \caption{Runtimes for MD4 testcase C with various SAT solvers}
    \label{tab:md4-C-runtimes}
  \end{center}
\end{table}

In Table~\ref{tab:md4-A-runtimes} it can be seen that the problem can be tackle
by all SAT solvers. lingeling-ats1o4 being a outlier can be ignored, because this
release is majorily concerned with providing debug information. As such it only
shows that printing information to stdout can make a major performance difference.

In Table~\ref{tab:md4-B-runtimes} we see that CryptoMiniSat~4.5.3, glucose~4.0
and glucose-syrup~4.0 couldn't solve the problem within the time limit of 1~day.
However, other SAT solver were still able to find a hash collision. Please recognize
that Table~\ref{tab:md4-A-runtimes} provides runtime results for the testcase
given in Table~\ref{fig:tcA}; equivalently Table~\ref{tab:md4-B-runtimes} for
Table~\ref{fig:tcB} and Table~\ref{tab:md4-C-runtimes} for Table~\ref{fig:tcC}.
Its caption gives an intuition how testcase B is more difficult than A and
C is more difficult than B.

We end up with the result, that the hash collision given in Table~\ref{fig:tcC}
can be solved by a limited set of modern SAT solvers. Of course the cryptanalyst
needs to figure out good starting points for the hash collision and encode them
in the differential characteristic, but this task is still considered practical,
because this task can be easily automated.

TODO: is phase -1 worth it?

TODO: simplification runtime is not part of runtime

\subsection{Improvements with differential description}
\label{sec:result-diff-desc}
%
Our next goal was to scale up to a more difficult problem. We considered SHA-256
which has a much larger internal state (at least by factor 2). So finding a hash
collision is more difficult and we considered further strategies.

Consider testcases 18~\ref{tab:18-t9}, 21~\ref{tab:21-t9}, 23~\ref{tab:23-t9}
and 24~\ref{tab:24-t9}. The number indicates how many steps are covered by this
testcase. We also tested a 27-round variant, but it is not listed here.
Most SAT solvers could not solve this problem in feasible time. Therefore we
excluded it from our list.

\begin{table}[!h]
  \begin{center}
    \begin{tabular}{lcc}
      SAT solver                & testcase      & runtime (in seconds) \\
    \hline
      minisat~2.2.0             & SHA-256, 18   & TODO \\
      cryptominisat~4.5.3       & SHA-256, 18   & TODO \\
      cryptominisat~5.0.0       & SHA-256, 18   & TODO \\
      glucose~4.0               & SHA-256, 18   & TODO \\
      glucose-syrup~4.0         & SHA-256, 18   & TODO \\
      lingeling-ats1            & SHA-256, 18   & TODO \\
      lingeling-ats1o1          & SHA-256, 18   & 25 \\
      lingeling-ats1o2          & SHA-256, 18   & TODO \\
      lingeling-ats1o4          & SHA-256, 18   & TODO \\
      plingeling-ats1o1         & SHA-256, 18   & TODO \\
      treeneling-ats1o1         & SHA-256, 18   & TODO
    \end{tabular}
    \caption{Runtimes for SHA-256 testcase 18 with various SAT solvers}
    \label{tab:SHA-256-18-runtimes}
  \end{center}
  \begin{center}
    \begin{tabular}{lcc}
      SAT solver                & testcase      & runtime (in seconds) \\
    \hline
      minisat~2.2.0             & SHA-256, 21   & TODO \\
      cryptominisat~4.5.3       & SHA-256, 21   & TODO \\
      cryptominisat~5.0.0       & SHA-256, 21   & TODO \\
      glucose~4.0               & SHA-256, 21   & TODO \\
      glucose-syrup~4.0         & SHA-256, 21   & TODO \\
      lingeling-ats1            & SHA-256, 21   & TODO \\
      lingeling-ats1o1          & SHA-256, 21   & 27,511 \\
      lingeling-ats1o2          & SHA-256, 21   & TODO \\
      lingeling-ats1o4          & SHA-256, 21   & TODO \\
      plingeling-ats1o1         & SHA-256, 21   & TODO \\
      treeneling-ats1o1         & SHA-256, 21   & TODO
    \end{tabular}
    \caption{Runtimes for SHA-256 testcase 21 with various SAT solvers}
    \label{tab:SHA-256-21-runtimes}
  \end{center}
  \begin{center}
    \begin{tabular}{lcc}
      SAT solver                & testcase      & runtime (in seconds) \\
    \hline
      minisat~2.2.0             & SHA-256, 23   & TODO \\
      cryptominisat~4.5.3       & SHA-256, 23   & TODO \\
      cryptominisat~5.0.0       & SHA-256, 23   & TODO \\
      glucose~4.0               & SHA-256, 23   & TODO \\
      glucose-syrup~4.0         & SHA-256, 23   & TODO \\
      lingeling-ats1            & SHA-256, 23   & TODO \\
      lingeling-ats1o1          & SHA-256, 23   & 59,227 \\
      lingeling-ats1o2          & SHA-256, 23   & TODO \\
      lingeling-ats1o4          & SHA-256, 23   & TODO \\
      plingeling-ats1o1         & SHA-256, 23   & TODO \\
      treeneling-ats1o1         & SHA-256, 23   & TODO
    \end{tabular}
    \caption{Runtimes for SHA-256 testcase 23 with various SAT solvers}
    \label{tab:SHA-256-23-runtimes}
  \end{center}
  \begin{center}
    \begin{tabular}{lcc}
      SAT solver                & testcase      & runtime (in seconds) \\
    \hline
      minisat~2.2.0             & SHA-256, 24   & TODO \\
      cryptominisat~4.5.3       & SHA-256, 24   & TODO \\
      cryptominisat~5.0.0       & SHA-256, 24   & TODO \\
      glucose~4.0               & SHA-256, 24   & TODO \\
      glucose-syrup~4.0         & SHA-256, 24   & TODO \\
      lingeling-ats1            & SHA-256, 24   & TODO \\
      lingeling-ats1o1          & SHA-256, 24   & 65,956 \\
      lingeling-ats1o2          & SHA-256, 24   & TODO \\
      lingeling-ats1o4          & SHA-256, 24   & TODO \\
      plingeling-ats1o1         & SHA-256, 24   & TODO \\
      treeneling-ats1o1         & SHA-256, 24   & TODO
    \end{tabular}
    \caption{Runtimes for SHA-256 testcase 24 with various SAT solvers}
    \label{tab:SHA-256-24-runtimes}
  \end{center}
\end{table}

In Tables~\ref{tab:SHA-256-18-runtimes} to \ref{tab:SHA-256-24-runtimes}
we see several results which illustrate TODO


Followingly we added the clauses which directly encode how differences
propagate in the hash algorithm; namely \enquote{differential description}
of Section~\ref{sec:enc-diff-desc}. If we compare the data, we can see
TODO

We continued by trying the influence the guessing strategy.

\subsection{Modifying the guessing strategy}
\label{sec:results-guessing}
%
As pointed out in Section~\ref{sec:enc-diff-desc-ocnf}, a best practice law of
differential cryptanalysis states that difference variables should be
assigned first. Afterwards propagation of actual values for the two
instances can take place.

To enforce such a strategy, we tried several approaches:
\begin{enumerate}
  \item
    Armin Biere provided us with a custom release of lingeling
    which enforces that a special set of variables is evaluated
    first. It is important that the CNF is still solved
    with usual SAT solver heuristics, because enforcing
    assignment of one variable after another leads to an increase
    in backtracking steps and restarts. Hence, we consider this
    release as a nice tradeoff. Difference variables are assigned
    \enquote{as early as possible, as late as necessary}.
  \item
    Given this custom SAT solver we considered a SAT design which
    requires the SAT solver to prefer a certain. This particular
    design with a special Boolean variable is explained in
    Section~\ref{sec:enc-diff-desc-eo}.
\end{enumerate}

\section{Related work}
\label{sec:results-related}
%
In my bachelor thesis~\cite{bach} we tried to integrate a SAT solver into
our department's existing tool which encodes propagation explicitly. This approach
was not very successful as restarts between hash algorithm rounds implied that
intermediate results by the SAT solver get lost.

Research was already done by Ilya Mironov and Lintao Zhang~\cite{mironov2006applications}
to apply SAT solvers to differential cryptanalysis specifically to find hash collision
in MD4. However whereas their basic approach seems to correspond to our approach described
in Section~\ref{sec:enc-original}, our implementation uses additional SAT design tweaks
to improve our results. Also because 10 years have gone since publication, SAT technology
has progressed and modern SAT solvers on modern hardware provide better results.



TODO justify: differential description improves runtime


\section{Conclusion}
\label{sec:conclusion}

We successfully found hash collisions for round-reduced MD4 and SHA-256.

\section{Contributions}
\label{sec:contributions}
%
To strengthen Reproducible Research, the source code and data resulting from this thesis is available online.
It allows the reader to run the experiments again and verify our claims.
We did our best to describe our hardware setup as accurately as possible.
At the following website, any results part of this project are collected:

\begin{quote}
  \url{http://lukas-prokop.at/proj/megosat/}
\end{quote}

Several subprojects are part of this master thesis:
\begin{description}
\item[algotocnf]\hfill{} \\
  A python library implementing the encoding described in Chapter~\ref{ch:enc}. \\[4pt]
  \textbf{Python3 library and program:} \url{https://github.com/prokls/algotocnf}
\item[cnf-hash]\hfill{} \\
  A standardized way to produce a unique hash for CNF files \\[4pt]
  \textbf{Go implementation:} \url{https://github.com/prokls/cnf-hash-go} \\
  \textbf{Python3 implementation:} \url{https://github.com/prokls/cnf-hash-py} \\
  \textbf{Testsuite:} \url{https://github.com/prokls/cnf-hash-tests2}
\item[cnf-analysis]\hfill{} \\
  Evaluate SAT features for a given CNF file. \\[4pt]
  \textbf{Go implementation:} \url{https://github.com/prokls/cnf-analysis-go} \\
  \textbf{Python3 implementation:} \url{https://github.com/prokls/cnf-analysis-py} \\
  \textbf{Testsuite:} \url{https://github.com/prokls/cnf-analysis-tests}
\end{description}
